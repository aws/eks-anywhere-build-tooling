From 6b3c6d7fbb56a346a7cbfedbdcc4ff01426047c0 Mon Sep 17 00:00:00 2001
From: Abhinav Pandey <abhinavmpandey08@gmail.com>
Date: Wed, 17 Jan 2024 09:28:18 -0800
Subject: [PATCH 28/36] Add support for in-place upgrade

---
 .../v1beta1/kubeadm_control_plane_types.go    |  18 +-
 .../v1beta2/kubeadm_control_plane_types.go    |  18 +-
 api/core/v1beta2/machinedeployment_types.go   |  19 +-
 api/core/v1beta2/zz_generated.openapi.go      |   2 +-
 .../cluster.x-k8s.io_clusterclasses.yaml      |   1 +
 .../crd/bases/cluster.x-k8s.io_clusters.yaml  |   1 +
 .../cluster.x-k8s.io_machinedeployments.yaml  |   9 +-
 ...cluster.x-k8s.io_kubeadmcontrolplanes.yaml |  18 +-
 ...x-k8s.io_kubeadmcontrolplanetemplates.yaml |  18 +-
 .../kubeadm/internal/controllers/update.go    |   8 +-
 .../internal/webhooks/kubeadmcontrolplane.go  |   4 +-
 .../webhooks/kubeadmcontrolplane_test.go      | 169 ++++++--
 .../machinedeployment_controller.go           |   4 +
 .../machinedeployment_controller_test.go      | 399 ++++++++++++++++++
 .../machinedeployment_inplace.go              |  70 +++
 .../machinedeployment_inplace_helper.go       | 115 +++++
 .../machinedeployment_inplace_test.go         | 114 +++++
 .../machinedeployment/mdutil/util.go          |   2 +-
 18 files changed, 937 insertions(+), 52 deletions(-)
 create mode 100644 internal/controllers/machinedeployment/machinedeployment_inplace.go
 create mode 100644 internal/controllers/machinedeployment/machinedeployment_inplace_helper.go
 create mode 100644 internal/controllers/machinedeployment/machinedeployment_inplace_test.go

diff --git a/api/controlplane/kubeadm/v1beta1/kubeadm_control_plane_types.go b/api/controlplane/kubeadm/v1beta1/kubeadm_control_plane_types.go
index b8dd22f19..e58d3a192 100644
--- a/api/controlplane/kubeadm/v1beta1/kubeadm_control_plane_types.go
+++ b/api/controlplane/kubeadm/v1beta1/kubeadm_control_plane_types.go
@@ -29,13 +29,16 @@ import (
 )
 
 // RolloutStrategyType defines the rollout strategies for a KubeadmControlPlane.
-// +kubebuilder:validation:Enum=RollingUpdate
+// +kubebuilder:validation:Enum=RollingUpdate;InPlace
 type RolloutStrategyType string
 
 const (
 	// RollingUpdateStrategyType replaces the old control planes by new one using rolling update
 	// i.e. gradually scale up or down the old control planes and scale up or down the new one.
 	RollingUpdateStrategyType RolloutStrategyType = "RollingUpdate"
+
+	// InPlaceUpgradeStrategyType updates the node in place by delegating the upgrade to an external entity.
+	InPlaceUpgradeStrategyType RolloutStrategyType = "InPlace"
 )
 
 const (
@@ -75,6 +78,11 @@ const (
 	// DefaultMinHealthyPeriod defines the default minimum period before we consider a remediation on a
 	// machine unrelated from the previous remediation.
 	DefaultMinHealthyPeriod = 1 * time.Hour
+
+	// InPlaceUpgradeAnnotation is used to denote that the KCP object needs to be in-place upgraded by an external entity.
+	// This annotation will be added to the KCP object when `rolloutStrategy.type` is set to `InPlace`.
+	// The external upgrader entity should watch for the annotation and trigger an upgrade when it's added.
+	InPlaceUpgradeAnnotation = "controlplane.clusters.x-k8s.io/in-place-upgrade-needed"
 )
 
 // KubeadmControlPlaneSpec defines the desired state of KubeadmControlPlane.
@@ -193,8 +201,12 @@ type RolloutBefore struct {
 // RolloutStrategy describes how to replace existing machines
 // with new ones.
 type RolloutStrategy struct {
-	// type of rollout. Currently the only supported strategy is
-	// "RollingUpdate".
+	// type of rollout strategy to use.
+	// Supported values:
+	// - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+	// i.e. gradually scale up or down the old control planes and scale up or down the new one.
+	// - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+	//
 	// Default is RollingUpdate.
 	// +optional
 	Type RolloutStrategyType `json:"type,omitempty"`
diff --git a/api/controlplane/kubeadm/v1beta2/kubeadm_control_plane_types.go b/api/controlplane/kubeadm/v1beta2/kubeadm_control_plane_types.go
index 966c33b58..341385eba 100644
--- a/api/controlplane/kubeadm/v1beta2/kubeadm_control_plane_types.go
+++ b/api/controlplane/kubeadm/v1beta2/kubeadm_control_plane_types.go
@@ -26,13 +26,16 @@ import (
 )
 
 // KubeadmControlPlaneRolloutStrategyType defines the rollout strategies for a KubeadmControlPlane.
-// +kubebuilder:validation:Enum=RollingUpdate
+// +kubebuilder:validation:Enum=RollingUpdate;InPlace
 type KubeadmControlPlaneRolloutStrategyType string
 
 const (
 	// RollingUpdateStrategyType replaces the old control planes by new one using rolling update
 	// i.e. gradually scale up or down the old control planes and scale up or down the new one.
 	RollingUpdateStrategyType KubeadmControlPlaneRolloutStrategyType = "RollingUpdate"
+
+	// InPlaceUpgradeStrategyType updates the node in place by delegating the upgrade to an external entity.
+	InPlaceUpgradeStrategyType KubeadmControlPlaneRolloutStrategyType = "InPlace"
 )
 
 const (
@@ -68,6 +71,11 @@ const (
 	// DefaultMinHealthyPeriodSeconds defines the default minimum period before we consider a remediation on a
 	// machine unrelated from the previous remediation.
 	DefaultMinHealthyPeriodSeconds = int32(60 * 60)
+
+	// InPlaceUpgradeAnnotation is used to denote that the KCP object needs to be in-place upgraded by an external entity.
+	// This annotation will be added to the KCP object when `rolloutStrategy.type` is set to `InPlace`.
+	// The external upgrader entity should watch for the annotation and trigger an upgrade when it's added.
+	InPlaceUpgradeAnnotation = "controlplane.clusters.x-k8s.io/in-place-upgrade-needed"
 )
 
 // KubeadmControlPlane's Available condition and corresponding reasons.
@@ -564,8 +572,12 @@ type KubeadmControlPlaneRolloutBeforeSpec struct {
 // with new ones.
 // +kubebuilder:validation:MinProperties=1
 type KubeadmControlPlaneRolloutStrategy struct {
-	// type of rollout. Currently the only supported strategy is
-	// "RollingUpdate".
+	// type of rollout strategy to use.
+	// Supported values:
+	// - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+	// i.e. gradually scale up or down the old control planes and scale up or down the new one.
+	// - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+	//
 	// Default is RollingUpdate.
 	// +required
 	Type KubeadmControlPlaneRolloutStrategyType `json:"type,omitempty"`
diff --git a/api/core/v1beta2/machinedeployment_types.go b/api/core/v1beta2/machinedeployment_types.go
index b7182c278..73bac8de0 100644
--- a/api/core/v1beta2/machinedeployment_types.go
+++ b/api/core/v1beta2/machinedeployment_types.go
@@ -32,7 +32,7 @@ const (
 )
 
 // MachineDeploymentRolloutStrategyType defines the type of MachineDeployment rollout strategies.
-// +kubebuilder:validation:Enum=RollingUpdate;OnDelete
+// +kubebuilder:validation:Enum=RollingUpdate;OnDelete;InPlace
 type MachineDeploymentRolloutStrategyType string
 
 const (
@@ -40,6 +40,9 @@ const (
 	// i.e. gradually scale down the old MachineSet and scale up the new one.
 	RollingUpdateMachineDeploymentStrategyType MachineDeploymentRolloutStrategyType = "RollingUpdate"
 
+	// InPlaceMachineDeploymentStrategyType upgrades the machines within the same MachineSet without rolling out any new nodes.
+	InPlaceMachineDeploymentStrategyType MachineDeploymentRolloutStrategyType = "InPlace"
+
 	// OnDeleteMachineDeploymentStrategyType replaces old MachineSets when the deletion of the associated machines are completed.
 	OnDeleteMachineDeploymentStrategyType MachineDeploymentRolloutStrategyType = "OnDelete"
 
@@ -56,6 +59,12 @@ const (
 	// proportions in case the deployment has surge replicas.
 	MaxReplicasAnnotation = "machinedeployment.clusters.x-k8s.io/max-replicas"
 
+	// MachineDeploymentInPlaceUpgradeAnnotation is used to denote that the MachineDeployment needs to be in-place upgraded by an external entity.
+	// This annotation will be added to the MD object when `strategy.type` is set to `InPlace`.
+	// The external upgrader entity should watch for the annotation and trigger an upgrade when it's added.
+	// Once the upgrade is complete, the external upgrade implementer is also responsible for removing this annotation.
+	MachineDeploymentInPlaceUpgradeAnnotation = "machinedeployment.clusters.x-k8s.io/in-place-upgrade-needed"
+
 	// MachineDeploymentUniqueLabel is used to uniquely identify the Machines of a MachineSet.
 	// The MachineDeployment controller will set this label on a MachineSet when it is created.
 	// The label is also applied to the Machines of the MachineSet and used in the MachineSet selector.
@@ -315,7 +324,13 @@ type MachineDeploymentRolloutSpec struct {
 // with new ones.
 // +kubebuilder:validation:MinProperties=1
 type MachineDeploymentRolloutStrategy struct {
-	// type of rollout. Allowed values are RollingUpdate and OnDelete.
+	// type of rollout strategy to use.
+	// Supported values:
+	// - `RollingUpdate`: replaces the old MachineSet by new one using rolling update
+	// i.e. gradually scale down the old MachineSet and scale up the new one.
+	// - `OnDelete`: replaces old MachineSets when the deletion of the associated machines are completed.
+	// - `InPlace`: upgrades the machines within the same MachineSet without rolling out any new nodes.
+	//
 	// Default is RollingUpdate.
 	// +required
 	Type MachineDeploymentRolloutStrategyType `json:"type,omitempty"`
diff --git a/api/core/v1beta2/zz_generated.openapi.go b/api/core/v1beta2/zz_generated.openapi.go
index 4a212f40d..6220c89ed 100644
--- a/api/core/v1beta2/zz_generated.openapi.go
+++ b/api/core/v1beta2/zz_generated.openapi.go
@@ -3259,7 +3259,7 @@ func schema_cluster_api_api_core_v1beta2_MachineDeploymentClassRolloutStrategy(r
 				Properties: map[string]spec.Schema{
 					"type": {
 						SchemaProps: spec.SchemaProps{
-							Description: "type of rollout. Allowed values are RollingUpdate and OnDelete. Default is RollingUpdate.",
+							Description: "type of rollout strategy to use. Supported values: - `RollingUpdate`: replaces the old MachineSet by new one using rolling update i.e. gradually scale down the old MachineSet and scale up the new one. - `OnDelete`: replaces old MachineSets when the deletion of the associated machines are completed. - `InPlace`: upgrades the machines within the same MachineSet without rolling out any new nodes.\n\nDefault is RollingUpdate.",
 							Type:        []string{"string"},
 							Format:      "",
 						},
diff --git a/config/crd/bases/cluster.x-k8s.io_clusterclasses.yaml b/config/crd/bases/cluster.x-k8s.io_clusterclasses.yaml
index b9dab0c42..9ab3408ef 100644
--- a/config/crd/bases/cluster.x-k8s.io_clusterclasses.yaml
+++ b/config/crd/bases/cluster.x-k8s.io_clusterclasses.yaml
@@ -4580,6 +4580,7 @@ spec:
                                   enum:
                                   - RollingUpdate
                                   - OnDelete
+                                  - InPlace
                                   type: string
                               required:
                               - type
diff --git a/config/crd/bases/cluster.x-k8s.io_clusters.yaml b/config/crd/bases/cluster.x-k8s.io_clusters.yaml
index 8ae016c06..24bcd5d65 100644
--- a/config/crd/bases/cluster.x-k8s.io_clusters.yaml
+++ b/config/crd/bases/cluster.x-k8s.io_clusters.yaml
@@ -3538,6 +3538,7 @@ spec:
                                       enum:
                                       - RollingUpdate
                                       - OnDelete
+                                      - InPlace
                                       type: string
                                   required:
                                   - type
diff --git a/config/crd/bases/cluster.x-k8s.io_machinedeployments.yaml b/config/crd/bases/cluster.x-k8s.io_machinedeployments.yaml
index 58cba1761..a51e19c97 100644
--- a/config/crd/bases/cluster.x-k8s.io_machinedeployments.yaml
+++ b/config/crd/bases/cluster.x-k8s.io_machinedeployments.yaml
@@ -2049,11 +2049,18 @@ spec:
                         type: object
                       type:
                         description: |-
-                          type of rollout. Allowed values are RollingUpdate and OnDelete.
+                          type of rollout strategy to use.
+                          Supported values:
+                          - `RollingUpdate`: replaces the old MachineSet by new one using rolling update
+                          i.e. gradually scale down the old MachineSet and scale up the new one.
+                          - `OnDelete`: replaces old MachineSets when the deletion of the associated machines are completed.
+                          - `InPlace`: upgrades the machines within the same MachineSet without rolling out any new nodes.
+
                           Default is RollingUpdate.
                         enum:
                         - RollingUpdate
                         - OnDelete
+                        - InPlace
                         type: string
                     required:
                     - type
diff --git a/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanes.yaml b/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanes.yaml
index 7f79e065f..2c44d2c44 100644
--- a/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanes.yaml
+++ b/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanes.yaml
@@ -5849,11 +5849,16 @@ spec:
                     type: object
                   type:
                     description: |-
-                      type of rollout. Currently the only supported strategy is
-                      "RollingUpdate".
+                      type of rollout strategy to use.
+                      Supported values:
+                      - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+                      i.e. gradually scale up or down the old control planes and scale up or down the new one.
+                      - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+
                       Default is RollingUpdate.
                     enum:
                     - RollingUpdate
+                    - InPlace
                     type: string
                 type: object
               version:
@@ -9348,11 +9353,16 @@ spec:
                         type: object
                       type:
                         description: |-
-                          type of rollout. Currently the only supported strategy is
-                          "RollingUpdate".
+                          type of rollout strategy to use.
+                          Supported values:
+                          - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+                          i.e. gradually scale up or down the old control planes and scale up or down the new one.
+                          - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+
                           Default is RollingUpdate.
                         enum:
                         - RollingUpdate
+                        - InPlace
                         type: string
                     required:
                     - type
diff --git a/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanetemplates.yaml b/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanetemplates.yaml
index 4d9b55dba..1ae5d2bb2 100644
--- a/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanetemplates.yaml
+++ b/controlplane/kubeadm/config/crd/bases/controlplane.cluster.x-k8s.io_kubeadmcontrolplanetemplates.yaml
@@ -4508,11 +4508,16 @@ spec:
                             type: object
                           type:
                             description: |-
-                              type of rollout. Currently the only supported strategy is
-                              "RollingUpdate".
+                              type of rollout strategy to use.
+                              Supported values:
+                              - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+                              i.e. gradually scale up or down the old control planes and scale up or down the new one.
+                              - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+
                               Default is RollingUpdate.
                             enum:
                             - RollingUpdate
+                            - InPlace
                             type: string
                         type: object
                     required:
@@ -7725,11 +7730,16 @@ spec:
                                 type: object
                               type:
                                 description: |-
-                                  type of rollout. Currently the only supported strategy is
-                                  "RollingUpdate".
+                                  type of rollout strategy to use.
+                                  Supported values:
+                                  - `RollingUpdate`: RollingUpdateStrategyType replaces the old control planes by new one using rolling update
+                                  i.e. gradually scale up or down the old control planes and scale up or down the new one.
+                                  - `InPlace`: updates the node in place by delegating the upgrade to an external entity.
+
                                   Default is RollingUpdate.
                                 enum:
                                 - RollingUpdate
+                                - InPlace
                                 type: string
                             required:
                             - type
diff --git a/controlplane/kubeadm/internal/controllers/update.go b/controlplane/kubeadm/internal/controllers/update.go
index d84fd5d9c..0984c24e7 100644
--- a/controlplane/kubeadm/internal/controllers/update.go
+++ b/controlplane/kubeadm/internal/controllers/update.go
@@ -18,6 +18,7 @@ package controllers
 
 import (
 	"context"
+	"time"
 
 	"github.com/blang/semver/v4"
 	"github.com/pkg/errors"
@@ -28,6 +29,7 @@ import (
 	controlplanev1 "sigs.k8s.io/cluster-api/api/controlplane/kubeadm/v1beta2"
 	"sigs.k8s.io/cluster-api/controlplane/kubeadm/internal"
 	"sigs.k8s.io/cluster-api/feature"
+	"sigs.k8s.io/cluster-api/util/annotations"
 	"sigs.k8s.io/cluster-api/util/collections"
 )
 
@@ -95,8 +97,12 @@ func (r *KubeadmControlPlaneReconciler) updateControlPlane(
 			return ctrl.Result{}, errors.Wrapf(err, "failed to update control plane")
 		}
 		return res, nil
+	case controlplanev1.InPlaceUpgradeStrategyType:
+		annotations.AddAnnotations(controlPlane.KCP, map[string]string{controlplanev1.InPlaceUpgradeAnnotation: "true"})
+		log.Info("RolloutStrategy type set to InPlaceUpgradeStrategyType, adding the annotation and requeuing", "annotation", controlplanev1.InPlaceUpgradeAnnotation)
+		return ctrl.Result{RequeueAfter: time.Second * 30}, nil
 	default:
-		log.Info("RolloutStrategy type is not set to RollingUpdate, unable to determine the strategy for rolling out machines")
+		log.Info("RolloutStrategy type is not set to RollingUpdateStrategyType or InPlaceUpgradeStrategyType, unable to determine the strategy for rolling out machines")
 		return ctrl.Result{}, nil
 	}
 }
diff --git a/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane.go b/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane.go
index 9c8c27bc1..3023fa3af 100644
--- a/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane.go
+++ b/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane.go
@@ -376,12 +376,12 @@ func validateRolloutAndCertValidityFields(rolloutSpec controlplanev1.KubeadmCont
 		return nil
 	}
 
-	if rolloutStrategy.Type != controlplanev1.RollingUpdateStrategyType {
+	if rolloutStrategy.Type != controlplanev1.RollingUpdateStrategyType && rolloutStrategy.Type != controlplanev1.InPlaceUpgradeStrategyType {
 		allErrs = append(
 			allErrs,
 			field.Required(
 				pathPrefix.Child("rollout", "strategy", "type"),
-				"only RollingUpdate is supported",
+				"only RollingUpdateStrategyType and InPlaceUpgradeStrategyType are supported",
 			),
 		)
 	}
diff --git a/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane_test.go b/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane_test.go
index 5d31bf678..50fcfd735 100644
--- a/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane_test.go
+++ b/controlplane/kubeadm/internal/webhooks/kubeadmcontrolplane_test.go
@@ -40,39 +40,148 @@ var (
 )
 
 func TestKubeadmControlPlaneDefault(t *testing.T) {
-	g := NewWithT(t)
-
-	kcp := &controlplanev1.KubeadmControlPlane{
-		ObjectMeta: metav1.ObjectMeta{
-			Namespace: "foo",
-		},
-		Spec: controlplanev1.KubeadmControlPlaneSpec{
-			Version: "v1.18.3",
-			MachineTemplate: controlplanev1.KubeadmControlPlaneMachineTemplate{
-				Spec: controlplanev1.KubeadmControlPlaneMachineTemplateSpec{
-					InfrastructureRef: clusterv1.ContractVersionedObjectReference{
-						APIGroup: "test",
-						Kind:     "UnknownInfraMachine",
-						Name:     "foo",
+	t.Run("should default to RollingUpdate strategy when not specified", func(t *testing.T) {
+		g := NewWithT(t)
+		kcp := &controlplanev1.KubeadmControlPlane{
+			ObjectMeta: metav1.ObjectMeta{
+				Namespace: "foo",
+			},
+			Spec: controlplanev1.KubeadmControlPlaneSpec{
+				Version: "v1.18.3",
+				MachineTemplate: controlplanev1.KubeadmControlPlaneMachineTemplate{
+					Spec: controlplanev1.KubeadmControlPlaneMachineTemplateSpec{
+						InfrastructureRef: clusterv1.ContractVersionedObjectReference{
+							APIGroup: "test",
+							Kind:     "UnknownInfraMachine",
+							Name:     "foo",
+						},
 					},
 				},
 			},
-		},
-	}
-	updateDefaultingValidationKCP := kcp.DeepCopy()
-	updateDefaultingValidationKCP.Spec.Version = "v1.18.3"
-	updateDefaultingValidationKCP.Spec.MachineTemplate.Spec.InfrastructureRef = clusterv1.ContractVersionedObjectReference{
-		APIGroup: "test",
-		Kind:     "UnknownInfraMachine",
-		Name:     "foo",
-	}
-	webhook := &KubeadmControlPlane{}
-	t.Run("for KubeadmControlPlane", util.CustomDefaultValidateTest(ctx, updateDefaultingValidationKCP, webhook))
-	g.Expect(webhook.Default(ctx, kcp)).To(Succeed())
-
-	g.Expect(kcp.Spec.Version).To(Equal("v1.18.3"))
-	g.Expect(kcp.Spec.Rollout.Strategy.Type).To(Equal(controlplanev1.RollingUpdateStrategyType))
-	g.Expect(kcp.Spec.Rollout.Strategy.RollingUpdate.MaxSurge.IntVal).To(Equal(int32(1)))
+		}
+		updateDefaultingValidationKCP := kcp.DeepCopy()
+		updateDefaultingValidationKCP.Spec.Version = "v1.18.3"
+		updateDefaultingValidationKCP.Spec.MachineTemplate.Spec.InfrastructureRef = clusterv1.ContractVersionedObjectReference{
+			APIGroup: "test",
+			Kind:     "UnknownInfraMachine",
+			Name:     "foo",
+		}
+		webhook := &KubeadmControlPlane{}
+		t.Run("for KubeadmControlPlane", util.CustomDefaultValidateTest(ctx, updateDefaultingValidationKCP, webhook))
+		g.Expect(webhook.Default(ctx, kcp)).To(Succeed())
+
+		g.Expect(kcp.Spec.Version).To(Equal("v1.18.3"))
+		g.Expect(kcp.Spec.Rollout.Strategy.Type).To(Equal(controlplanev1.RollingUpdateStrategyType))
+		g.Expect(kcp.Spec.Rollout.Strategy.RollingUpdate.MaxSurge.IntVal).To(Equal(int32(1)))
+	})
+
+	t.Run("should preserve InPlace strategy and not set MaxSurge", func(t *testing.T) {
+		g := NewWithT(t)
+		kcp := &controlplanev1.KubeadmControlPlane{
+			ObjectMeta: metav1.ObjectMeta{
+				Namespace: "foo",
+			},
+			Spec: controlplanev1.KubeadmControlPlaneSpec{
+				Version: "v1.18.3",
+				MachineTemplate: controlplanev1.KubeadmControlPlaneMachineTemplate{
+					Spec: controlplanev1.KubeadmControlPlaneMachineTemplateSpec{
+						InfrastructureRef: clusterv1.ContractVersionedObjectReference{
+							APIGroup: "test",
+							Kind:     "UnknownInfraMachine",
+							Name:     "foo",
+						},
+					},
+				},
+				Rollout: controlplanev1.KubeadmControlPlaneRolloutSpec{
+					Strategy: controlplanev1.KubeadmControlPlaneRolloutStrategy{
+						Type: controlplanev1.InPlaceUpgradeStrategyType,
+					},
+				},
+			},
+		}
+		webhook := &KubeadmControlPlane{}
+		g.Expect(webhook.Default(ctx, kcp)).To(Succeed())
+
+		g.Expect(kcp.Spec.Version).To(Equal("v1.18.3"))
+		g.Expect(kcp.Spec.Rollout.Strategy.Type).To(Equal(controlplanev1.InPlaceUpgradeStrategyType))
+		// MaxSurge should not be set for InPlace strategy
+		g.Expect(kcp.Spec.Rollout.Strategy.RollingUpdate.MaxSurge).To(BeNil())
+	})
+
+	t.Run("should preserve RollingUpdate strategy with custom MaxSurge", func(t *testing.T) {
+		g := NewWithT(t)
+		customMaxSurge := intstr.FromInt32(3)
+		kcp := &controlplanev1.KubeadmControlPlane{
+			ObjectMeta: metav1.ObjectMeta{
+				Namespace: "foo",
+			},
+			Spec: controlplanev1.KubeadmControlPlaneSpec{
+				Version: "v1.18.3",
+				MachineTemplate: controlplanev1.KubeadmControlPlaneMachineTemplate{
+					Spec: controlplanev1.KubeadmControlPlaneMachineTemplateSpec{
+						InfrastructureRef: clusterv1.ContractVersionedObjectReference{
+							APIGroup: "test",
+							Kind:     "UnknownInfraMachine",
+							Name:     "foo",
+						},
+					},
+				},
+				Rollout: controlplanev1.KubeadmControlPlaneRolloutSpec{
+					Strategy: controlplanev1.KubeadmControlPlaneRolloutStrategy{
+						Type: controlplanev1.RollingUpdateStrategyType,
+						RollingUpdate: controlplanev1.KubeadmControlPlaneRolloutStrategyRollingUpdate{
+							MaxSurge: &customMaxSurge,
+						},
+					},
+				},
+			},
+		}
+		webhook := &KubeadmControlPlane{}
+		g.Expect(webhook.Default(ctx, kcp)).To(Succeed())
+
+		g.Expect(kcp.Spec.Version).To(Equal("v1.18.3"))
+		g.Expect(kcp.Spec.Rollout.Strategy.Type).To(Equal(controlplanev1.RollingUpdateStrategyType))
+		// Custom MaxSurge should be preserved
+		g.Expect(kcp.Spec.Rollout.Strategy.RollingUpdate.MaxSurge.IntVal).To(Equal(int32(3)))
+	})
+
+	t.Run("should default type to RollingUpdate when only MaxSurge is specified", func(t *testing.T) {
+		g := NewWithT(t)
+		customMaxSurge := intstr.FromInt32(0)
+		kcp := &controlplanev1.KubeadmControlPlane{
+			ObjectMeta: metav1.ObjectMeta{
+				Namespace: "foo",
+			},
+			Spec: controlplanev1.KubeadmControlPlaneSpec{
+				Version: "v1.18.3",
+				MachineTemplate: controlplanev1.KubeadmControlPlaneMachineTemplate{
+					Spec: controlplanev1.KubeadmControlPlaneMachineTemplateSpec{
+						InfrastructureRef: clusterv1.ContractVersionedObjectReference{
+							APIGroup: "test",
+							Kind:     "UnknownInfraMachine",
+							Name:     "foo",
+						},
+					},
+				},
+				Rollout: controlplanev1.KubeadmControlPlaneRolloutSpec{
+					Strategy: controlplanev1.KubeadmControlPlaneRolloutStrategy{
+						// Type not specified
+						RollingUpdate: controlplanev1.KubeadmControlPlaneRolloutStrategyRollingUpdate{
+							MaxSurge: &customMaxSurge,
+						},
+					},
+				},
+			},
+		}
+		webhook := &KubeadmControlPlane{}
+		g.Expect(webhook.Default(ctx, kcp)).To(Succeed())
+
+		g.Expect(kcp.Spec.Version).To(Equal("v1.18.3"))
+		// Type should be defaulted to RollingUpdate
+		g.Expect(kcp.Spec.Rollout.Strategy.Type).To(Equal(controlplanev1.RollingUpdateStrategyType))
+		// Custom MaxSurge should be preserved
+		g.Expect(kcp.Spec.Rollout.Strategy.RollingUpdate.MaxSurge.IntVal).To(Equal(int32(0)))
+	})
 }
 
 func TestKubeadmControlPlaneValidateCreate(t *testing.T) {
diff --git a/internal/controllers/machinedeployment/machinedeployment_controller.go b/internal/controllers/machinedeployment/machinedeployment_controller.go
index 2b6a0f349..326727432 100644
--- a/internal/controllers/machinedeployment/machinedeployment_controller.go
+++ b/internal/controllers/machinedeployment/machinedeployment_controller.go
@@ -317,6 +317,10 @@ func (r *Reconciler) reconcile(ctx context.Context, s *scope) error {
 		return r.rolloutOnDelete(ctx, md, s.machineSets, s.machines, templateExists)
 	}
 
+	if md.Spec.Rollout.Strategy.Type == clusterv1.InPlaceMachineDeploymentStrategyType {
+		return r.rolloutInPlace(ctx, md, s.machineSets, templateExists)
+	}
+
 	return errors.Errorf("unexpected deployment strategy type: %s", md.Spec.Rollout.Strategy.Type)
 }
 
diff --git a/internal/controllers/machinedeployment/machinedeployment_controller_test.go b/internal/controllers/machinedeployment/machinedeployment_controller_test.go
index 9c1a13dd9..9e177541a 100644
--- a/internal/controllers/machinedeployment/machinedeployment_controller_test.go
+++ b/internal/controllers/machinedeployment/machinedeployment_controller_test.go
@@ -24,9 +24,11 @@ import (
 	corev1 "k8s.io/api/core/v1"
 	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
+	"k8s.io/apimachinery/pkg/types"
 	"k8s.io/client-go/tools/record"
 	"k8s.io/client-go/util/retry"
 	utilfeature "k8s.io/component-base/featuregate/testing"
+	"k8s.io/utils/pointer"
 	"k8s.io/utils/ptr"
 	"sigs.k8s.io/controller-runtime/pkg/client"
 	"sigs.k8s.io/controller-runtime/pkg/client/fake"
@@ -36,6 +38,8 @@ import (
 	"sigs.k8s.io/cluster-api/controllers/external"
 	"sigs.k8s.io/cluster-api/feature"
 	"sigs.k8s.io/cluster-api/util"
+	"sigs.k8s.io/cluster-api/util/annotations"
+	"sigs.k8s.io/cluster-api/util/conditions"
 	v1beta1conditions "sigs.k8s.io/cluster-api/util/conditions/deprecated/v1beta1"
 	"sigs.k8s.io/cluster-api/util/patch"
 	"sigs.k8s.io/cluster-api/util/test/builder"
@@ -43,6 +47,7 @@ import (
 
 const (
 	machineDeploymentNamespace = "md-test"
+	version128                 = "v1.28.0"
 )
 
 var _ reconcile.Reconciler = &Reconciler{}
@@ -855,6 +860,400 @@ func updateMachineDeployment(ctx context.Context, c client.Client, md *clusterv1
 	})
 }
 
+func TestMachineDeploymentReconcilerInPlace(t *testing.T) {
+	setup := func(t *testing.T, g *WithT) (*corev1.Namespace, *clusterv1.Cluster) {
+		t.Helper()
+
+		t.Log("Creating the namespace")
+		ns, err := env.CreateNamespace(ctx, machineDeploymentNamespace)
+		g.Expect(err).ToNot(HaveOccurred())
+
+		t.Log("Creating the Cluster")
+		cluster := &clusterv1.Cluster{ObjectMeta: metav1.ObjectMeta{Namespace: ns.Name, Name: "test-cluster"}}
+		g.Expect(env.Create(ctx, cluster)).To(Succeed())
+
+		t.Log("Creating the Cluster Kubeconfig Secret")
+		g.Expect(env.CreateKubeconfigSecret(ctx, cluster)).To(Succeed())
+
+		return ns, cluster
+	}
+
+	teardown := func(t *testing.T, g *WithT, ns *corev1.Namespace, cluster *clusterv1.Cluster) {
+		t.Helper()
+
+		t.Log("Deleting the Cluster")
+		g.Expect(env.Delete(ctx, cluster)).To(Succeed())
+		t.Log("Deleting the namespace")
+		g.Expect(env.Delete(ctx, ns)).To(Succeed())
+	}
+
+	t.Run("Should reconcile a MachineDeployment with InPlace upgrade", func(t *testing.T) {
+		g := NewWithT(t)
+		namespace, testCluster := setup(t, g)
+		defer teardown(t, g, namespace, testCluster)
+
+		labels := map[string]string{
+			"foo":                      "bar",
+			clusterv1.ClusterNameLabel: testCluster.Name,
+		}
+		deployment := &clusterv1.MachineDeployment{
+			ObjectMeta: metav1.ObjectMeta{
+				GenerateName: "md-",
+				Namespace:    namespace.Name,
+				Labels: map[string]string{
+					clusterv1.ClusterNameLabel: testCluster.Name,
+				},
+			},
+			Spec: clusterv1.MachineDeploymentSpec{
+				ClusterName: testCluster.Name,
+				Replicas:    pointer.Int32(2),
+				Selector: metav1.LabelSelector{
+					// We're using the same labels for spec.selector and spec.template.labels.
+					// The labels are later changed and we will use the initial labels later to
+					// verify that all original MachineSets have been deleted.
+					MatchLabels: labels,
+				},
+				Rollout: clusterv1.MachineDeploymentRolloutSpec{
+					Strategy: clusterv1.MachineDeploymentRolloutStrategy{
+						Type: clusterv1.InPlaceMachineDeploymentStrategyType,
+					},
+				},
+				Template: clusterv1.MachineTemplateSpec{
+					ObjectMeta: clusterv1.ObjectMeta{
+						Labels: labels,
+					},
+					Spec: clusterv1.MachineSpec{
+						ClusterName: testCluster.Name,
+						Version:     version128,
+						InfrastructureRef: clusterv1.ContractVersionedObjectReference{
+							APIGroup: "infrastructure.cluster.x-k8s.io",
+							Kind:     "GenericInfrastructureMachineTemplate",
+							Name:     "md-template",
+						},
+						Bootstrap: clusterv1.Bootstrap{
+							DataSecretName: pointer.String("data-secret-name"),
+						},
+					},
+				},
+			},
+		}
+		msListOpts := []client.ListOption{
+			client.InNamespace(namespace.Name),
+			client.MatchingLabels(labels),
+		}
+
+		// Create infrastructure template resource.
+		infraResource := map[string]interface{}{
+			"kind":       "GenericInfrastructureMachine",
+			"apiVersion": "infrastructure.cluster.x-k8s.io/v1beta2",
+			"metadata":   map[string]interface{}{},
+			"spec": map[string]interface{}{
+				"size": "3xlarge",
+			},
+		}
+		infraTmpl := &unstructured.Unstructured{
+			Object: map[string]interface{}{
+				"kind":       "GenericInfrastructureMachineTemplate",
+				"apiVersion": "infrastructure.cluster.x-k8s.io/v1beta2",
+				"metadata": map[string]interface{}{
+					"name":      "md-template",
+					"namespace": namespace.Name,
+				},
+				"spec": map[string]interface{}{
+					"template": infraResource,
+				},
+			},
+		}
+		t.Log("Creating the infrastructure template")
+		g.Expect(env.Create(ctx, infraTmpl)).To(Succeed())
+
+		// Create the MachineDeployment object and expect Reconcile to be called.
+		t.Log("Creating the MachineDeployment")
+		g.Expect(env.Create(ctx, deployment)).To(Succeed())
+		defer func() {
+			t.Log("Deleting the MachineDeployment")
+			g.Expect(env.Delete(ctx, deployment)).To(Succeed())
+		}()
+
+		t.Log("Verifying the MachineDeployment has a cluster label and ownerRef")
+		g.Eventually(func() bool {
+			key := client.ObjectKey{Name: deployment.Name, Namespace: deployment.Namespace}
+			if err := env.Get(ctx, key, deployment); err != nil {
+				return false
+			}
+			if len(deployment.Labels) == 0 || deployment.Labels[clusterv1.ClusterNameLabel] != testCluster.Name {
+				return false
+			}
+			if len(deployment.OwnerReferences) == 0 || deployment.OwnerReferences[0].Name != testCluster.Name {
+				return false
+			}
+			return true
+		}, timeout).Should(BeTrue())
+
+		// Verify that the MachineSet was created.
+		t.Log("Verifying the MachineSet was created")
+		machineSets := &clusterv1.MachineSetList{}
+		g.Eventually(func() int {
+			if err := env.List(ctx, machineSets, msListOpts...); err != nil {
+				return -1
+			}
+			return len(machineSets.Items)
+		}, timeout).Should(BeEquivalentTo(1))
+
+		t.Log("Verifying the linked infrastructure template has a cluster owner reference")
+		g.Eventually(func() bool {
+			obj, err := external.GetObjectFromContractVersionedRef(ctx, env, deployment.Spec.Template.Spec.InfrastructureRef, deployment.Namespace)
+			if err != nil {
+				return false
+			}
+
+			return util.HasOwnerRef(obj.GetOwnerReferences(), metav1.OwnerReference{
+				APIVersion: clusterv1.GroupVersion.String(),
+				Kind:       "Cluster",
+				Name:       testCluster.Name,
+				UID:        testCluster.UID,
+			})
+		}, timeout).Should(BeTrue())
+
+		t.Log("Verify MachineSet has expected replicas and version")
+		firstMachineSet := machineSets.Items[0]
+		g.Expect(*firstMachineSet.Spec.Replicas).To(BeEquivalentTo(2))
+		g.Expect(firstMachineSet.Spec.Template.Spec.Version).To(BeEquivalentTo(version128))
+
+		t.Log("Verify MachineSet has expected ClusterNameLabel and MachineDeploymentNameLabel")
+		g.Expect(firstMachineSet.Labels[clusterv1.ClusterNameLabel]).To(Equal(testCluster.Name))
+		g.Expect(firstMachineSet.Labels[clusterv1.MachineDeploymentNameLabel]).To(Equal(deployment.Name))
+
+		t.Log("Verify expected number of Machines are created")
+		machines := &clusterv1.MachineList{}
+		g.Eventually(func() int {
+			if err := env.List(ctx, machines, client.InNamespace(namespace.Name)); err != nil {
+				return -1
+			}
+			return len(machines.Items)
+		}, timeout).Should(BeEquivalentTo(*deployment.Spec.Replicas))
+
+		t.Log("Verify Machines have expected ClusterNameLabel, MachineDeploymentNameLabel and MachineSetNameLabel")
+		for _, m := range machines.Items {
+			g.Expect(m.Labels[clusterv1.ClusterNameLabel]).To(Equal(testCluster.Name))
+			g.Expect(m.Labels[clusterv1.MachineDeploymentNameLabel]).To(Equal(deployment.Name))
+			g.Expect(m.Labels[clusterv1.MachineSetNameLabel]).To(Equal(firstMachineSet.Name))
+		}
+
+		//
+		// Delete firstMachineSet and expect Reconcile to be called to replace it.
+		//
+		t.Log("Deleting the initial MachineSet")
+		g.Expect(env.Delete(ctx, &firstMachineSet)).To(Succeed())
+		g.Eventually(func() bool {
+			if err := env.List(ctx, machineSets, msListOpts...); err != nil {
+				return false
+			}
+			for _, ms := range machineSets.Items {
+				if ms.UID == firstMachineSet.UID {
+					return false
+				}
+			}
+			return len(machineSets.Items) > 0
+		}, timeout).Should(BeTrue())
+
+		//
+		// Scale the MachineDeployment and expect Reconcile to be called.
+		//
+		secondMachineSet := machineSets.Items[0]
+		t.Log("Scaling the MachineDeployment to 3 replicas")
+		desiredMachineDeploymentReplicas := int32(3)
+		modifyFunc := func(d *clusterv1.MachineDeployment) {
+			d.Spec.Replicas = pointer.Int32(desiredMachineDeploymentReplicas)
+		}
+		g.Expect(updateMachineDeployment(ctx, env, deployment, modifyFunc)).To(Succeed())
+		g.Eventually(func() int {
+			key := client.ObjectKey{Name: secondMachineSet.Name, Namespace: secondMachineSet.Namespace}
+			if err := env.Get(ctx, key, &secondMachineSet); err != nil {
+				return -1
+			}
+			return int(*secondMachineSet.Spec.Replicas)
+		}, timeout).Should(BeEquivalentTo(desiredMachineDeploymentReplicas))
+
+		//
+		// Update the InfraStructureRef of the MachineDeployment, expect Reconcile to be called and a new MachineSet to appear.
+		//
+
+		t.Log("Updating the InfrastructureRef on the MachineDeployment")
+		// Create the InfrastructureTemplate
+		// Create infrastructure template resource.
+		infraTmpl2 := &unstructured.Unstructured{
+			Object: map[string]interface{}{
+				"kind":       "GenericInfrastructureMachineTemplate",
+				"apiVersion": "infrastructure.cluster.x-k8s.io/v1beta2",
+				"metadata": map[string]interface{}{
+					"name":      "md-template-2",
+					"namespace": namespace.Name,
+				},
+				"spec": map[string]interface{}{
+					"template": map[string]interface{}{
+						"kind":       "GenericInfrastructureMachine",
+						"apiVersion": "infrastructure.cluster.x-k8s.io/v1beta2",
+						"metadata":   map[string]interface{}{},
+						"spec": map[string]interface{}{
+							"size": "5xlarge",
+						},
+					},
+				},
+			},
+		}
+		t.Log("Creating the infrastructure template")
+		g.Expect(env.Create(ctx, infraTmpl2)).To(Succeed())
+
+		infraTmpl2Ref := clusterv1.ContractVersionedObjectReference{
+			APIGroup: "infrastructure.cluster.x-k8s.io",
+			Kind:     "GenericInfrastructureMachineTemplate",
+			Name:     "md-template-2",
+		}
+		modifyFunc = func(d *clusterv1.MachineDeployment) { d.Spec.Template.Spec.InfrastructureRef = infraTmpl2Ref }
+		g.Expect(updateMachineDeployment(ctx, env, deployment, modifyFunc)).To(Succeed())
+		g.Eventually(func() int {
+			if err := env.List(ctx, machineSets, msListOpts...); err != nil {
+				return -1
+			}
+			return len(machineSets.Items)
+		}, timeout).Should(BeEquivalentTo(1))
+
+		// Expect InPlace annotation to be added to the MD object.
+		g.Eventually(func() bool {
+			md := &clusterv1.MachineDeployment{}
+			if err := env.Get(ctx, types.NamespacedName{Name: deployment.Name, Namespace: deployment.Namespace}, md); err != nil {
+				return false
+			}
+			return annotations.HasAnnotation(md, clusterv1.MachineDeploymentInPlaceUpgradeAnnotation)
+		}, timeout).Should(BeTrue())
+
+		t.Log("Setting MachineSet template to match MachineDeployment template and removing the in-place annotation")
+		md := &clusterv1.MachineDeployment{}
+		g.Expect(env.Get(ctx, types.NamespacedName{Name: deployment.Name, Namespace: deployment.Namespace}, md)).To(Succeed())
+		ms := machineSets.Items[0]
+		patchHelper, err := patch.NewHelper(&ms, env)
+		g.Expect(err).ToNot(HaveOccurred())
+		ms.Spec.Template.Spec = md.Spec.Template.Spec
+		g.Expect(patchHelper.Patch(ctx, &ms)).To(Succeed())
+
+		modifyFunc = func(d *clusterv1.MachineDeployment) {
+			delete(d.Annotations, clusterv1.MachineDeploymentInPlaceUpgradeAnnotation)
+		}
+		g.Expect(updateMachineDeployment(ctx, env, deployment, modifyFunc)).To(Succeed())
+		g.Eventually(func() map[string]string {
+			md := &clusterv1.MachineDeployment{}
+			if err := env.Get(ctx, types.NamespacedName{Name: deployment.Name, Namespace: deployment.Namespace}, md); err != nil {
+				return nil
+			}
+			return md.Annotations
+		}, timeout).ShouldNot(HaveKey(clusterv1.MachineDeploymentInPlaceUpgradeAnnotation))
+		g.Eventually(func() int32 {
+			md := &clusterv1.MachineDeployment{}
+			if err := env.Get(ctx, types.NamespacedName{Name: deployment.Name, Namespace: deployment.Namespace}, md); err != nil {
+				return -1
+			}
+			return *md.Status.UpToDateReplicas
+		}, timeout).Should(BeEquivalentTo(*md.Spec.Replicas))
+
+		// Update the Labels of the MachineDeployment, expect Reconcile to be called and the MachineSet to be updated in-place.
+		t.Log("Setting a label on the MachineDeployment")
+		modifyFunc = func(d *clusterv1.MachineDeployment) { d.Spec.Template.Labels["updated"] = "true" }
+		g.Expect(updateMachineDeployment(ctx, env, deployment, modifyFunc)).To(Succeed())
+		g.Eventually(func(g Gomega) {
+			g.Expect(env.List(ctx, machineSets, msListOpts...)).To(Succeed())
+			// Verify we still only have 1 MachineSet.
+			g.Expect(machineSets.Items).To(HaveLen(1))
+			// Verify that the new MachineSet gets the updated labels.
+			g.Expect(machineSets.Items[0].Spec.Template.Labels).To(HaveKeyWithValue("updated", "true"))
+		}, timeout).Should(Succeed())
+
+		// Update the NodeDrainTimout, NodeDeletionTimeout, NodeVolumeDetachTimeout of the MachineDeployment,
+		// expect the Reconcile to be called and the MachineSet to be updated in-place.
+		t.Log("Setting NodeDrainTimout, NodeDeletionTimeout, NodeVolumeDetachTimeout on the MachineDeployment")
+		duration10s := int32(10)
+		modifyFunc = func(d *clusterv1.MachineDeployment) {
+			d.Spec.Template.Spec.Deletion.NodeDrainTimeoutSeconds = &duration10s
+			d.Spec.Template.Spec.Deletion.NodeDeletionTimeoutSeconds = &duration10s
+			d.Spec.Template.Spec.Deletion.NodeVolumeDetachTimeoutSeconds = &duration10s
+		}
+		g.Expect(updateMachineDeployment(ctx, env, deployment, modifyFunc)).To(Succeed())
+		g.Eventually(func(g Gomega) {
+			g.Expect(env.List(ctx, machineSets, msListOpts...)).Should(Succeed())
+			// Verify we still only have 1 MachineSets.
+			g.Expect(machineSets.Items).To(HaveLen(1))
+			// Verify the NodeDrainTimeout value is updated
+			g.Expect(machineSets.Items[0].Spec.Template.Spec.Deletion.NodeDrainTimeoutSeconds).Should(And(
+				Not(BeNil()),
+				HaveValue(Equal(duration10s)),
+			), "NodeDrainTimout value does not match expected")
+			// Verify the NodeDeletionTimeout value is updated
+			g.Expect(machineSets.Items[0].Spec.Template.Spec.Deletion.NodeDeletionTimeoutSeconds).Should(And(
+				Not(BeNil()),
+				HaveValue(Equal(duration10s)),
+			), "NodeDeletionTimeout value does not match expected")
+			// Verify the NodeVolumeDetachTimeout value is updated
+			g.Expect(machineSets.Items[0].Spec.Template.Spec.Deletion.NodeVolumeDetachTimeoutSeconds).Should(And(
+				Not(BeNil()),
+				HaveValue(Equal(duration10s)),
+			), "NodeVolumeDetachTimeout value does not match expected")
+		}).Should(Succeed())
+
+		// Verify that all the MachineSets have the expected OwnerRef.
+		t.Log("Verifying MachineSet owner references")
+		g.Eventually(func() bool {
+			if err := env.List(ctx, machineSets, msListOpts...); err != nil {
+				return false
+			}
+			for i := 0; i < len(machineSets.Items); i++ {
+				ms := machineSets.Items[0]
+				if !metav1.IsControlledBy(&ms, deployment) || metav1.GetControllerOf(&ms).Kind != "MachineDeployment" {
+					return false
+				}
+			}
+			return true
+		}, timeout).Should(BeTrue())
+
+		t.Log("Locating the newest MachineSet")
+		newestMachineSet := &machineSets.Items[0]
+		g.Expect(newestMachineSet).NotTo(BeNil())
+
+		t.Log("Verifying new MachineSet has desired number of replicas")
+		g.Eventually(func() bool {
+			g.Expect(env.List(ctx, machineSets, msListOpts...)).Should(Succeed())
+			newms := machineSets.Items[0]
+			// Set the all non-deleted machines as ready with a NodeRef, so the MachineSet controller can proceed
+			// to properly set AvailableReplicas.
+			foundMachines := &clusterv1.MachineList{}
+			g.Expect(env.List(ctx, foundMachines, client.InNamespace(namespace.Name))).To(Succeed())
+			for i := 0; i < len(foundMachines.Items); i++ {
+				m := foundMachines.Items[i]
+				if !m.DeletionTimestamp.IsZero() {
+					continue
+				}
+				// Skip over Machines controlled by other (previous) MachineSets
+				if !metav1.IsControlledBy(&m, &newms) {
+					continue
+				}
+				providerID := fakeInfrastructureRefProvisioned(m.Spec.InfrastructureRef, m.Namespace, infraResource, g)
+				fakeMachineNodeRef(&m, providerID, g)
+			}
+
+			return newms.Status.Replicas == &desiredMachineDeploymentReplicas
+		}, timeout*5).Should(BeTrue())
+
+		t.Log("Verifying MachineDeployment has correct Conditions")
+		g.Eventually(func() bool {
+			key := client.ObjectKey{Name: deployment.Name, Namespace: deployment.Namespace}
+			g.Expect(env.Get(ctx, key, deployment)).To(Succeed())
+			return conditions.IsTrue(deployment, clusterv1.MachineDeploymentAvailableCondition)
+		}, timeout).Should(BeTrue())
+
+		// Validate that the controller set the cluster name label in selector.
+		g.Expect(deployment.Status.Selector).To(ContainSubstring(testCluster.Name))
+	})
+}
+
 func TestReconciler_reconcileDelete(t *testing.T) {
 	labels := map[string]string{
 		"some": "labelselector",
diff --git a/internal/controllers/machinedeployment/machinedeployment_inplace.go b/internal/controllers/machinedeployment/machinedeployment_inplace.go
new file mode 100644
index 000000000..0c1a18e83
--- /dev/null
+++ b/internal/controllers/machinedeployment/machinedeployment_inplace.go
@@ -0,0 +1,70 @@
+package machinedeployment
+
+import (
+	"context"
+
+	ctrl "sigs.k8s.io/controller-runtime"
+
+	clusterv1 "sigs.k8s.io/cluster-api/api/core/v1beta2"
+	"sigs.k8s.io/cluster-api/internal/controllers/machinedeployment/mdutil"
+	"sigs.k8s.io/cluster-api/util/annotations"
+)
+
+func (r *Reconciler) rolloutInPlace(ctx context.Context, md *clusterv1.MachineDeployment, msList []*clusterv1.MachineSet, templateExists bool) (reterr error) {
+	log := ctrl.LoggerFrom(ctx)
+
+	// If there are no MachineSets for a MachineDeployment, either this is a create operation for a new
+	// MachineDeployment or the MachineSets were manually deleted. In either case, a new MachineSet should be created
+	// as there are no MachineSets that can be in-place upgraded.
+	// If there are already MachineSets present, we shouldn't try to create a new MachineSet as that would trigger a rollout.
+	// Instead, we should try to get latest MachineSet that matches the MachineDeployment.Spec.Template
+	// If no such MachineSet exists yet, this means the MachineSet hasn't been in-place upgraded yet.
+	// The external in-place upgrade implementer is responsible for updating the latest MachineSet's template
+	// after in-place upgrade of all worker nodes belonging to the MD is complete.
+	// Once the MachineSet is updated, this function will return the latest MachineSet that matches the
+	// MachineDeployment template and thus we can deduce that the in-place upgrade is complete.
+	newMachineSetNeeded := len(msList) == 0
+	newMachineSet, oldMachineSets, err := r.getAllMachineSetsAndSyncRevision(ctx, md, msList, newMachineSetNeeded, templateExists)
+	if err != nil {
+		return err
+	}
+
+	allMSs := oldMachineSets
+
+	if newMachineSet == nil {
+		log.Info("Changes detected, InPlace upgrade strategy detected, adding the annotation")
+		annotations.AddAnnotations(md, map[string]string{clusterv1.MachineDeploymentInPlaceUpgradeAnnotation: "true"})
+	} else if !annotations.HasAnnotation(md, clusterv1.MachineDeploymentInPlaceUpgradeAnnotation) {
+		// If in-place upgrade annotation is no longer present, attempt to scale up the new MachineSet if necessary
+		// and scale down the old MachineSets if necessary.
+		// Note that if there are no scaling operations required, this else if block will be a no-op.
+
+		allMSs = append(allMSs, newMachineSet)
+
+		// Scale up, if we can.
+		if err := r.reconcileNewMachineSet(ctx, allMSs, newMachineSet, md); err != nil {
+			return err
+		}
+
+		if err := r.syncDeploymentStatus(allMSs, newMachineSet, md); err != nil {
+			return err
+		}
+
+		// Scale down, if we can.
+		if err := r.reconcileOldMachineSets(ctx, allMSs, oldMachineSets, newMachineSet, md); err != nil {
+			return err
+		}
+	}
+
+	if err := r.syncDeploymentStatus(allMSs, newMachineSet, md); err != nil {
+		return err
+	}
+
+	if mdutil.DeploymentComplete(md, &md.Status) {
+		if err := r.cleanupDeployment(ctx, oldMachineSets, md); err != nil {
+			return err
+		}
+	}
+
+	return nil
+}
diff --git a/internal/controllers/machinedeployment/machinedeployment_inplace_helper.go b/internal/controllers/machinedeployment/machinedeployment_inplace_helper.go
new file mode 100644
index 000000000..d602bffdc
--- /dev/null
+++ b/internal/controllers/machinedeployment/machinedeployment_inplace_helper.go
@@ -0,0 +1,115 @@
+package machinedeployment
+
+import (
+	"context"
+
+	"github.com/pkg/errors"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+
+	clusterv1 "sigs.k8s.io/cluster-api/api/core/v1beta2"
+	"sigs.k8s.io/cluster-api/internal/controllers/machinedeployment/mdutil"
+)
+
+// getAllMachineSetsAndSyncRevision returns all the machine sets for the provided deployment (new and all old).
+// This function uses v1.12.1's rollout planner to properly compute desired state for all MachineSets,
+// which includes propagating in-place mutable fields, updating revision annotations, and creating new
+// MachineSets if needed.
+func (r *Reconciler) getAllMachineSetsAndSyncRevision(ctx context.Context, md *clusterv1.MachineDeployment, msList []*clusterv1.MachineSet, createIfNotExisted, templateExists bool) (*clusterv1.MachineSet, []*clusterv1.MachineSet, error) {
+	// Use the v1.12.1 rollout planner to:
+	// 1. Find newMS and oldMSs
+	// 2. Compute desired state with in-place mutable fields propagated
+	// 3. Handle revision annotations
+	// 4. Create newMS if needed
+	planner := newRolloutPlanner(r.Client, r.RuntimeClient, r.canUpdateMachineSetCache)
+	if err := planner.init(ctx, md, msList, nil, createIfNotExisted, templateExists); err != nil {
+		return nil, nil, err
+	}
+
+	// If no new MachineSet was found/created, return early
+	// This can happen when createIfNotExisted is false
+	if planner.newMS == nil {
+		return nil, planner.oldMSs, nil
+	}
+
+	// Apply the planner's computed state to MachineSets
+	// This will:
+	// - Create new MachineSet if it doesn't exist
+	// - Update existing MachineSets to propagate in-place mutable fields
+	// - Sync revision annotations
+	if err := r.createOrUpdateMachineSetsAndSyncMachineDeploymentRevision(ctx, planner); err != nil {
+		return nil, nil, err
+	}
+
+	return planner.newMS, planner.oldMSs, nil
+}
+
+// reconcileNewMachineSet handles reconciliation of the new MachineSet for in-place upgrade strategy.
+// It scales the new MachineSet up if needed.
+func (r *Reconciler) reconcileNewMachineSet(ctx context.Context, allMSs []*clusterv1.MachineSet, newMS *clusterv1.MachineSet, deployment *clusterv1.MachineDeployment) error {
+	if deployment.Spec.Replicas == nil {
+		return errors.Errorf("spec.replicas for MachineDeployment %v is nil, this is unexpected", client.ObjectKeyFromObject(deployment))
+	}
+
+	if newMS.Spec.Replicas == nil {
+		return errors.Errorf("spec.replicas for MachineSet %v is nil, this is unexpected", client.ObjectKeyFromObject(newMS))
+	}
+
+	if *(newMS.Spec.Replicas) == *(deployment.Spec.Replicas) {
+		// Scaling not required.
+		return nil
+	}
+
+	if *(newMS.Spec.Replicas) > *(deployment.Spec.Replicas) {
+		// Scale down.
+		return r.scaleMachineSet(ctx, newMS, *(deployment.Spec.Replicas), deployment)
+	}
+
+	// v1.12.1's NewMSNewReplicas now returns 3 values: (replicas, reason, error)
+	newReplicasCount, _, err := mdutil.NewMSNewReplicas(deployment, allMSs, *newMS.Spec.Replicas)
+	if err != nil {
+		return err
+	}
+	return r.scaleMachineSet(ctx, newMS, newReplicasCount, deployment)
+}
+
+// reconcileOldMachineSets handles reconciliation of old MachineSets for in-place upgrade strategy.
+// It scales down old MachineSets if the new MachineSet is ready.
+func (r *Reconciler) reconcileOldMachineSets(ctx context.Context, allMSs []*clusterv1.MachineSet, oldMSs []*clusterv1.MachineSet, newMS *clusterv1.MachineSet, deployment *clusterv1.MachineDeployment) error {
+	if deployment.Spec.Replicas == nil {
+		return errors.Errorf("spec.replicas for MachineDeployment %v is nil, this is unexpected",
+			client.ObjectKeyFromObject(deployment))
+	}
+
+	if newMS.Spec.Replicas == nil {
+		return errors.Errorf("spec.replicas for MachineSet %v is nil, this is unexpected",
+			client.ObjectKeyFromObject(newMS))
+	}
+
+	oldMachinesCount := mdutil.GetReplicaCountForMachineSets(oldMSs)
+	if oldMachinesCount == 0 {
+		// Can't scale down further
+		return nil
+	}
+
+	// For in-place upgrades, we can scale down old MachineSets once the new MachineSet
+	// has the desired number of replicas and they are available.
+	// This is simpler than the rolling update strategy because we're not creating new machines,
+	// just updating existing ones in place.
+	if *(newMS.Spec.Replicas) == *(deployment.Spec.Replicas) {
+		// New MachineSet has desired replicas, scale down old MachineSets
+		for _, oldMS := range oldMSs {
+			if oldMS.Spec.Replicas == nil {
+				return errors.Errorf("spec.replicas for MachineSet %v is nil, this is unexpected",
+					client.ObjectKeyFromObject(oldMS))
+			}
+			if *(oldMS.Spec.Replicas) == 0 {
+				continue
+			}
+			if err := r.scaleMachineSet(ctx, oldMS, 0, deployment); err != nil {
+				return err
+			}
+		}
+	}
+
+	return nil
+}
diff --git a/internal/controllers/machinedeployment/machinedeployment_inplace_test.go b/internal/controllers/machinedeployment/machinedeployment_inplace_test.go
new file mode 100644
index 000000000..5c5f34290
--- /dev/null
+++ b/internal/controllers/machinedeployment/machinedeployment_inplace_test.go
@@ -0,0 +1,114 @@
+package machinedeployment
+
+import (
+	"testing"
+
+	. "github.com/onsi/gomega"
+	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
+	"k8s.io/client-go/tools/record"
+	"k8s.io/utils/pointer"
+	clusterv1 "sigs.k8s.io/cluster-api/api/core/v1beta2"
+	"sigs.k8s.io/controller-runtime/pkg/client"
+	"sigs.k8s.io/controller-runtime/pkg/client/fake"
+)
+
+const (
+	mdName     = "my-md"
+	msName     = "my-ms"
+	version129 = "v1.29.0"
+)
+
+func getMachineDeployment(name string, version string, replicas int32) *clusterv1.MachineDeployment {
+	return &clusterv1.MachineDeployment{
+		ObjectMeta: metav1.ObjectMeta{
+			Name: name,
+		},
+		Spec: clusterv1.MachineDeploymentSpec{
+			Rollout: clusterv1.MachineDeploymentRolloutSpec{
+				Strategy: clusterv1.MachineDeploymentRolloutStrategy{
+					Type: clusterv1.InPlaceMachineDeploymentStrategyType,
+				},
+			},
+			Replicas: pointer.Int32(replicas),
+			Template: clusterv1.MachineTemplateSpec{
+				Spec: clusterv1.MachineSpec{
+					ClusterName: "my-cluster",
+					Version:     version,
+				},
+			},
+		},
+	}
+}
+
+func getMachineSet(name string, version string, replicas int32) *clusterv1.MachineSet {
+	return &clusterv1.MachineSet{
+		ObjectMeta: metav1.ObjectMeta{
+			Name: name,
+		},
+		Spec: clusterv1.MachineSetSpec{
+			Replicas: pointer.Int32(replicas),
+			Template: clusterv1.MachineTemplateSpec{
+				Spec: clusterv1.MachineSpec{
+					ClusterName: "my-cluster",
+					Version:     version,
+				},
+			},
+		},
+	}
+}
+
+func TestRolloutInPlace(t *testing.T) {
+	testCases := []struct {
+		name               string
+		machineDeployment  *clusterv1.MachineDeployment
+		msList             []*clusterv1.MachineSet
+		annotationExpected bool
+		expectErr          bool
+		templateExists     bool
+	}{
+		{
+			name:               "MD template matches MS template",
+			machineDeployment:  getMachineDeployment(mdName, version128, 2),
+			msList:             []*clusterv1.MachineSet{getMachineSet(msName, version128, 2)},
+			annotationExpected: false,
+			expectErr:          false,
+			templateExists:     true,
+		},
+		{
+			name:               "MD template doesn't MS template",
+			machineDeployment:  getMachineDeployment(mdName, version128, 2),
+			msList:             []*clusterv1.MachineSet{getMachineSet(msName, version129, 2)},
+			annotationExpected: true,
+			expectErr:          true,
+			templateExists:     false,
+		},
+	}
+
+	for _, tc := range testCases {
+		t.Run(tc.name, func(t *testing.T) {
+			g := NewWithT(t)
+
+			resources := []client.Object{
+				tc.machineDeployment,
+			}
+
+			for key := range tc.msList {
+				resources = append(resources, tc.msList[key])
+			}
+
+			r := &Reconciler{
+				Client:   fake.NewClientBuilder().WithObjects(resources...).Build(),
+				recorder: record.NewFakeRecorder(32),
+			}
+
+			err := r.rolloutInPlace(ctx, tc.machineDeployment, tc.msList, tc.templateExists)
+			if tc.expectErr {
+				g.Expect(err).To(HaveOccurred())
+			}
+
+			_, ok := tc.machineDeployment.Annotations[clusterv1.MachineDeploymentInPlaceUpgradeAnnotation]
+			g.Expect(ok).To(Equal(tc.annotationExpected))
+		})
+	}
+
+}
diff --git a/internal/controllers/machinedeployment/mdutil/util.go b/internal/controllers/machinedeployment/mdutil/util.go
index 4a96ff222..1170cb3a0 100644
--- a/internal/controllers/machinedeployment/mdutil/util.go
+++ b/internal/controllers/machinedeployment/mdutil/util.go
@@ -682,7 +682,7 @@ func NewMSNewReplicas(deployment *clusterv1.MachineDeployment, allMSs []*cluster
 		// Do not exceed the number of desired replicas.
 		scaleUpCount = min(scaleUpCount, *(deployment.Spec.Replicas)-newMSReplicas)
 		return newMSReplicas + scaleUpCount, fmt.Sprintf("%d current Machines < %d MachineDeployment spec.replicas + %d maxSurge", currentMachineCount, ptr.Deref(deployment.Spec.Replicas, 0), maxSurge), nil
-	case clusterv1.OnDeleteMachineDeploymentStrategyType:
+	case clusterv1.OnDeleteMachineDeploymentStrategyType, clusterv1.InPlaceMachineDeploymentStrategyType:
 		// Find the total number of machines
 		currentMachineCount := TotalMachineSetsReplicaSum(allMSs)
 		if currentMachineCount >= *(deployment.Spec.Replicas) {
-- 
2.50.1 (Apple Git-155)

