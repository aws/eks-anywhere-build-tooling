From cab7d20c3d8a9d25e50989abfab824e07dd1327d Mon Sep 17 00:00:00 2001
From: Rajashree Mandaogane <mandaor@amazon.com>
Date: Mon, 28 Jun 2021 13:44:50 -0700
Subject: [PATCH 02/40] Add unstacked etcd support

Unstacked etcd: API and config changes

Unstacked etcd: Changes in CAPI core controllers

This commit adds the following changes in the cluster controller:
* A change in reconcileControlPlane to check if the cluster is using managed
external etcd, and if etcd is not ready then pause the control plane provisioning.
* A new phase in cluster controller's phases for reconciling the etcd cluster. If the
etcd cluster is ready then this phase will resume control plane provisioning

This commit also adds the following change in the machine controller:
* The machine controller upon creation of the first etcd machine will save its IP.

Unstacked etcd: Changes in KCP controller

The KubeadmControlPlane controller will get the external etcd endpoints
from the object referenced by cluster.spec.managedExternalEtcdRef.
The validating webhook will allow the external etcd endpoints to be updated.

Unstacked etcd: Change in docker infra provider

Docker is the only infrastructure provider that performs a kubectl patch on the k8s
node corresponding to a Machine. This needs to be skipped for etcd machines since they
are not registered as nodes and do not run kubelet.

Unstacked etcd: Ignore nodeRef check for etcd machines during clusterctl move

Clusterctl before beginning the move checks if all CAPI objects are
ready and provisioned. One of these checks is for Machine.Status.NodeRef field.
This check needs to be skipped for etcd machines since they are not registered
as Kubernetes nodes so they don't have a corresponding Node.

Delete managed external etcd cluster last

Update KCP controller to use renamed etcd endpoints field

The field 'endpoint' on EtcdadmCluster's status has been renamed
to 'endpoints'. This commit updates the KCP controller to use the
renamed field

cr https://code.amazon.com/reviews/CR-54310674

Add external etcd api changes to v1beta1 capi CRDs

Fix etcdMachine to cluster reconciler so it listens on Machine events

cr: https://code.amazon.com/reviews/CR-56463335

Add external etcd api to v1alpha4

Fix watch on machine object for etcdMachine to cluster mapper

While cherry-picking commits from 0.3.19 branch the watch got modified
by mistake. This commit fixes it by changing it back to watching Machine
objects.

Retain update permission on etcdadmcluster for KCP controller

KCP controller updates the etcdadmcluster object once KCP upgrade is completed.
It needs update permission on etcdadmcluster object for this.
We previously had added this permission, it got dropped while rebasing
commits on the new 1.0.1 branch. This commit adds back the permission.
---
 api/v1beta1/cluster_types.go                  |  14 ++
 api/v1beta1/condition_consts.go               |  16 ++
 api/v1beta1/machine_types.go                  |   3 +
 cmd/clusterctl/client/cluster/mover.go        |   3 +-
 .../crd/bases/cluster.x-k8s.io_clusters.yaml  | 144 ++++++++++++++++++
 config/rbac/role.yaml                         |  15 ++
 controllers/external/util.go                  |  10 ++
 controlplane/kubeadm/config/rbac/role.yaml    |   9 ++
 .../internal/controllers/controller.go        |  51 ++++++-
 internal/apis/core/v1alpha3/cluster_types.go  |  14 ++
 .../apis/core/v1alpha3/condition_consts.go    |  16 ++
 internal/apis/core/v1alpha3/conversion.go     |  13 ++
 internal/apis/core/v1alpha3/machine_types.go  |   3 +
 .../core/v1alpha3/zz_generated.conversion.go  |   6 +
 internal/apis/core/v1alpha4/cluster_types.go  |  14 ++
 .../apis/core/v1alpha4/condition_consts.go    |  16 ++
 internal/apis/core/v1alpha4/machine_types.go  |   3 +
 .../core/v1alpha4/zz_generated.conversion.go  |   6 +
 .../controllers/cluster/cluster_controller.go |  85 ++++++++++-
 .../cluster/cluster_controller_phases.go      | 105 +++++++++++++
 .../cluster/cluster_controller_test.go        | 136 +++++++++++++++++
 .../machine/machine_controller_noderef.go     |   8 +
 .../machine_controller_noderef_test.go        |  46 ++++++
 .../machine/machine_controller_phases.go      | 117 ++++++++++++++
 .../machine/machine_controller_status.go      |   7 +
 util/collections/machine_filters.go           |  26 ++++
 util/secret/certificates.go                   |   3 +
 util/secret/consts.go                         |   2 +
 util/util.go                                  |   6 +
 29 files changed, 886 insertions(+), 11 deletions(-)

diff --git a/api/v1beta1/cluster_types.go b/api/v1beta1/cluster_types.go
index bbce8f181..1199e1171 100644
--- a/api/v1beta1/cluster_types.go
+++ b/api/v1beta1/cluster_types.go
@@ -478,6 +478,11 @@ type ClusterSpec struct {
 	// +optional
 	ControlPlaneRef *corev1.ObjectReference `json:"controlPlaneRef,omitempty"`
 
+	// ManagedExternalEtcdRef is an optional reference to an etcd provider resource that holds details
+	// for provisioning an external etcd cluster
+	// +optional
+	ManagedExternalEtcdRef *corev1.ObjectReference `json:"managedExternalEtcdRef,omitempty"`
+
 	// infrastructureRef is a reference to a provider-specific resource that holds the details
 	// for provisioning infrastructure for a cluster in said provider.
 	// +optional
@@ -896,6 +901,15 @@ type ClusterStatus struct {
 	// +optional
 	ObservedGeneration int64 `json:"observedGeneration,omitempty"`
 
+	// ManagedExternalEtcdInitialized indicates that first etcd member's IP address is set by machine controller,
+	// so remaining etcd members can lookup the address to join the cluster
+	// +optional
+	ManagedExternalEtcdInitialized bool `json:"managedExternalEtcdInitialized"`
+
+	// ManagedExternalEtcdReady indicates external etcd cluster is fully provisioned
+	// +optional
+	ManagedExternalEtcdReady bool `json:"managedExternalEtcdReady"`
+
 	// v1beta2 groups all the fields that will be added or modified in Cluster's status with the V1Beta2 version.
 	// +optional
 	V1Beta2 *ClusterV1Beta2Status `json:"v1beta2,omitempty"`
diff --git a/api/v1beta1/condition_consts.go b/api/v1beta1/condition_consts.go
index b2797402e..30e3dd928 100644
--- a/api/v1beta1/condition_consts.go
+++ b/api/v1beta1/condition_consts.go
@@ -286,6 +286,22 @@ const (
 	ScalingDownReason = "ScalingDown"
 )
 
+// Conditions used by the Etcd provider objects
+const (
+	// ManagedExternalEtcdClusterInitializedCondition is set once the first member of an etcd cluster is provisioned and running
+	ManagedExternalEtcdClusterInitializedCondition ConditionType = "ManagedEtcdInitialized"
+
+	// ManagedExternalEtcdClusterReadyCondition indicates if the etcd cluster is ready and all members have passed healthchecks.
+	ManagedExternalEtcdClusterReadyCondition ConditionType = "ManagedEtcdReady"
+
+	// WaitingForEtcdClusterInitializedReason (Severity=Info) documents a cluster waiting for the etcd cluster
+	// to report successful etcd cluster initialization.
+	WaitingForEtcdClusterInitializedReason = "WaitingForEtcdClusterProviderInitialized"
+
+	// EtcdHealthCheckFailedReason (Severity=Error) documents that healthcheck on an etcd member failed
+	EtcdHealthCheckFailedReason = "EtcdMemberHealthCheckFailed"
+)
+
 // Conditions and condition reasons for Clusters with a managed Topology.
 const (
 	// TopologyReconciledCondition provides evidence about the reconciliation of a Cluster topology into
diff --git a/api/v1beta1/machine_types.go b/api/v1beta1/machine_types.go
index fccc584fe..583d2d6f9 100644
--- a/api/v1beta1/machine_types.go
+++ b/api/v1beta1/machine_types.go
@@ -30,6 +30,9 @@ const (
 	// MachineControlPlaneLabel is the label set on machines or related objects that are part of a control plane.
 	MachineControlPlaneLabel = "cluster.x-k8s.io/control-plane"
 
+	//MachineEtcdClusterLabelName is the label set on machines or related objects that are part of an etcd cluster
+	MachineEtcdClusterLabelName = "cluster.x-k8s.io/etcd-cluster"
+
 	// ExcludeNodeDrainingAnnotation annotation explicitly skips node draining if set.
 	ExcludeNodeDrainingAnnotation = "machine.cluster.x-k8s.io/exclude-node-draining"
 
diff --git a/cmd/clusterctl/client/cluster/mover.go b/cmd/clusterctl/client/cluster/mover.go
index 5e30202d7..d775dc847 100644
--- a/cmd/clusterctl/client/cluster/mover.go
+++ b/cmd/clusterctl/client/cluster/mover.go
@@ -270,7 +270,8 @@ func (o *objectMover) checkProvisioningCompleted(ctx context.Context, graph *obj
 			return err
 		}
 
-		if machineObj.Status.NodeRef == nil {
+		_, isEtcdMachine := machineObj.Labels[clusterv1.MachineEtcdClusterLabelName]
+		if machineObj.Status.NodeRef == nil && !isEtcdMachine {
 			errList = append(errList, errors.Errorf("cannot start the move operation while %q %s/%s is still provisioning the node", machineObj.GroupVersionKind(), machineObj.GetNamespace(), machineObj.GetName()))
 		}
 	}
diff --git a/config/crd/bases/cluster.x-k8s.io_clusters.yaml b/config/crd/bases/cluster.x-k8s.io_clusters.yaml
index 4ad163561..08476c22f 100644
--- a/config/crd/bases/cluster.x-k8s.io_clusters.yaml
+++ b/config/crd/bases/cluster.x-k8s.io_clusters.yaml
@@ -187,6 +187,45 @@ spec:
                     type: string
                 type: object
                 x-kubernetes-map-type: atomic
+              managedExternalEtcdRef:
+                description: ManagedExternalEtcdRef is an optional reference to an
+                  etcd provider resource that holds details for provisioning an external
+                  etcd cluster
+                properties:
+                  apiVersion:
+                    description: API version of the referent.
+                    type: string
+                  fieldPath:
+                    description: 'If referring to a piece of an object instead of
+                      an entire object, this string should contain a valid JSON/Go
+                      field access statement, such as desiredState.manifest.containers[2].
+                      For example, if the object reference is to a container within
+                      a pod, this would take on a value like: "spec.containers{name}"
+                      (where "name" refers to the name of the container that triggered
+                      the event) or if no container name is specified "spec.containers[2]"
+                      (container with index 2 in this pod). This syntax is chosen
+                      only to have some well-defined way of referencing a part of
+                      an object. TODO: this design is not final and this field is
+                      subject to change in the future.'
+                    type: string
+                  kind:
+                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
+                    type: string
+                  name:
+                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names'
+                    type: string
+                  namespace:
+                    description: 'Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/'
+                    type: string
+                  resourceVersion:
+                    description: 'Specific resourceVersion to which this reference
+                      is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency'
+                    type: string
+                  uid:
+                    description: 'UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids'
+                    type: string
+                type: object
+                x-kubernetes-map-type: atomic
               paused:
                 description: paused can be used to prevent controllers from processing
                   the Cluster and all its associated objects.
@@ -281,6 +320,15 @@ spec:
                 description: infrastructureReady is the state of the infrastructure
                   provider.
                 type: boolean
+              managedExternalEtcdInitialized:
+                description: ManagedExternalEtcdInitialized indicates that first etcd
+                  member's IP address is set by machine controller, so remaining etcd
+                  members can lookup the address to join the cluster
+                type: boolean
+              managedExternalEtcdReady:
+                description: ManagedExternalEtcdReady indicates external etcd cluster
+                  is fully provisioned
+                type: boolean
               observedGeneration:
                 description: observedGeneration is the latest generation observed
                   by the controller.
@@ -473,6 +521,45 @@ spec:
                     type: string
                 type: object
                 x-kubernetes-map-type: atomic
+              managedExternalEtcdRef:
+                description: ManagedExternalEtcdRef is an optional reference to an
+                  etcd provider resource that holds details for provisioning an external
+                  etcd cluster
+                properties:
+                  apiVersion:
+                    description: API version of the referent.
+                    type: string
+                  fieldPath:
+                    description: 'If referring to a piece of an object instead of
+                      an entire object, this string should contain a valid JSON/Go
+                      field access statement, such as desiredState.manifest.containers[2].
+                      For example, if the object reference is to a container within
+                      a pod, this would take on a value like: "spec.containers{name}"
+                      (where "name" refers to the name of the container that triggered
+                      the event) or if no container name is specified "spec.containers[2]"
+                      (container with index 2 in this pod). This syntax is chosen
+                      only to have some well-defined way of referencing a part of
+                      an object. TODO: this design is not final and this field is
+                      subject to change in the future.'
+                    type: string
+                  kind:
+                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
+                    type: string
+                  name:
+                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names'
+                    type: string
+                  namespace:
+                    description: 'Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/'
+                    type: string
+                  resourceVersion:
+                    description: 'Specific resourceVersion to which this reference
+                      is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency'
+                    type: string
+                  uid:
+                    description: 'UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids'
+                    type: string
+                type: object
+                x-kubernetes-map-type: atomic
               paused:
                 description: paused can be used to prevent controllers from processing
                   the Cluster and all its associated objects.
@@ -690,6 +777,15 @@ spec:
                 description: infrastructureReady is the state of the infrastructure
                   provider.
                 type: boolean
+              managedExternalEtcdInitialized:
+                description: ManagedExternalEtcdInitialized indicates that first etcd
+                  member's IP address is set by machine controller, so remaining etcd
+                  members can lookup the address to join the cluster
+                type: boolean
+              managedExternalEtcdReady:
+                description: ManagedExternalEtcdReady indicates external etcd cluster
+                  is fully provisioned
+                type: boolean
               observedGeneration:
                 description: observedGeneration is the latest generation observed
                   by the controller.
@@ -913,6 +1009,45 @@ spec:
                     type: string
                 type: object
                 x-kubernetes-map-type: atomic
+              managedExternalEtcdRef:
+                description: ManagedExternalEtcdRef is an optional reference to an
+                  etcd provider resource that holds details for provisioning an external
+                  etcd cluster
+                properties:
+                  apiVersion:
+                    description: API version of the referent.
+                    type: string
+                  fieldPath:
+                    description: 'If referring to a piece of an object instead of
+                      an entire object, this string should contain a valid JSON/Go
+                      field access statement, such as desiredState.manifest.containers[2].
+                      For example, if the object reference is to a container within
+                      a pod, this would take on a value like: "spec.containers{name}"
+                      (where "name" refers to the name of the container that triggered
+                      the event) or if no container name is specified "spec.containers[2]"
+                      (container with index 2 in this pod). This syntax is chosen
+                      only to have some well-defined way of referencing a part of
+                      an object. TODO: this design is not final and this field is
+                      subject to change in the future.'
+                    type: string
+                  kind:
+                    description: 'Kind of the referent. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
+                    type: string
+                  name:
+                    description: 'Name of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names'
+                    type: string
+                  namespace:
+                    description: 'Namespace of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/'
+                    type: string
+                  resourceVersion:
+                    description: 'Specific resourceVersion to which this reference
+                      is made, if any. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency'
+                    type: string
+                  uid:
+                    description: 'UID of the referent. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#uids'
+                    type: string
+                type: object
+                x-kubernetes-map-type: atomic
               paused:
                 description: paused can be used to prevent controllers from processing
                   the Cluster and all its associated objects.
@@ -1782,6 +1917,15 @@ spec:
                 description: infrastructureReady is the state of the infrastructure
                   provider.
                 type: boolean
+              managedExternalEtcdInitialized:
+                description: ManagedExternalEtcdInitialized indicates that first etcd
+                  member's IP address is set by machine controller, so remaining etcd
+                  members can lookup the address to join the cluster
+                type: boolean
+              managedExternalEtcdReady:
+                description: ManagedExternalEtcdReady indicates external etcd cluster
+                  is fully provisioned
+                type: boolean
               observedGeneration:
                 description: observedGeneration is the latest generation observed
                   by the controller.
diff --git a/config/rbac/role.yaml b/config/rbac/role.yaml
index 76b7016c3..aff1b694a 100644
--- a/config/rbac/role.yaml
+++ b/config/rbac/role.yaml
@@ -56,6 +56,21 @@ rules:
   - subjectaccessreviews
   verbs:
   - create
+- apiGroups:
+  - bootstrap.cluster.x-k8s.io
+  - controlplane.cluster.x-k8s.io
+  - etcdcluster.cluster.x-k8s.io
+  - infrastructure.cluster.x-k8s.io
+  resources:
+  - '*'
+  verbs:
+  - create
+  - delete
+  - get
+  - list
+  - patch
+  - update
+  - watch
 - apiGroups:
   - cluster.x-k8s.io
   resources:
diff --git a/controllers/external/util.go b/controllers/external/util.go
index 61c94ad2d..40d80bfa7 100644
--- a/controllers/external/util.go
+++ b/controllers/external/util.go
@@ -257,3 +257,13 @@ func IsInitialized(obj *unstructured.Unstructured) (bool, error) {
 	}
 	return initialized && found, nil
 }
+
+func GetExternalEtcdEndpoints(externalEtcd *unstructured.Unstructured) (string, bool, error) {
+	endpoints, found, err := unstructured.NestedString(externalEtcd.Object, "status", "endpoints")
+	if err != nil {
+		return "", false, errors.Wrapf(err, "failed to get external etcd endpoints from %v %q", externalEtcd.GroupVersionKind(),
+			externalEtcd.GetName())
+	}
+
+	return endpoints, found, nil
+}
diff --git a/controlplane/kubeadm/config/rbac/role.yaml b/controlplane/kubeadm/config/rbac/role.yaml
index ef8f27924..3b3b11ef2 100644
--- a/controlplane/kubeadm/config/rbac/role.yaml
+++ b/controlplane/kubeadm/config/rbac/role.yaml
@@ -79,3 +79,12 @@ rules:
   - patch
   - update
   - watch
+- apiGroups:
+  - etcdcluster.cluster.x-k8s.io
+  resources:
+  - '*'
+  verbs:
+  - get
+  - list
+  - update
+  - watch
diff --git a/controlplane/kubeadm/internal/controllers/controller.go b/controlplane/kubeadm/internal/controllers/controller.go
index 0dfe36031..967bda0e8 100644
--- a/controlplane/kubeadm/internal/controllers/controller.go
+++ b/controlplane/kubeadm/internal/controllers/controller.go
@@ -19,6 +19,7 @@ package controllers
 import (
 	"context"
 	"fmt"
+	"reflect"
 	"sort"
 	"strings"
 	"time"
@@ -43,6 +44,7 @@ import (
 	clusterv1 "sigs.k8s.io/cluster-api/api/v1beta1"
 	bootstrapv1 "sigs.k8s.io/cluster-api/bootstrap/kubeadm/api/v1beta1"
 	"sigs.k8s.io/cluster-api/controllers/clustercache"
+	"sigs.k8s.io/cluster-api/controllers/external"
 	controlplanev1 "sigs.k8s.io/cluster-api/controlplane/kubeadm/api/v1beta1"
 	"sigs.k8s.io/cluster-api/controlplane/kubeadm/internal"
 	expv1 "sigs.k8s.io/cluster-api/exp/api/v1beta1"
@@ -74,6 +76,7 @@ const (
 // +kubebuilder:rbac:groups=cluster.x-k8s.io,resources=machines;machines/status,verbs=get;list;watch;create;update;patch;delete
 // +kubebuilder:rbac:groups=cluster.x-k8s.io,resources=machinepools,verbs=get;list;watch
 // +kubebuilder:rbac:groups=apiextensions.k8s.io,resources=customresourcedefinitions,verbs=get;list;watch
+// +kubebuilder:rbac:groups=etcdcluster.cluster.x-k8s.io,resources=*,verbs=get;list;watch;update
 
 // KubeadmControlPlaneReconciler reconciles a KubeadmControlPlane object.
 type KubeadmControlPlaneReconciler struct {
@@ -199,6 +202,31 @@ func (r *KubeadmControlPlaneReconciler) Reconcile(ctx context.Context, req ctrl.
 		log.Error(err, "Failed to configure the patch helper")
 		return ctrl.Result{Requeue: true}, nil
 	}
+	if cluster.Spec.ManagedExternalEtcdRef != nil {
+		etcdRef := cluster.Spec.ManagedExternalEtcdRef
+		externalEtcd, err := external.Get(ctx, r.Client, etcdRef, cluster.Namespace)
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+		endpoints, found, err := external.GetExternalEtcdEndpoints(externalEtcd)
+		if err != nil {
+			return ctrl.Result{}, errors.Wrapf(err, "failed to get endpoint field from %v", externalEtcd.GetName())
+		}
+		if !found {
+			log.Info("Etcd endpoints not available")
+			return ctrl.Result{Requeue: true}, nil
+		}
+		currentEtcdEndpoints := strings.Split(endpoints, ",")
+		sort.Strings(currentEtcdEndpoints)
+		currentKCPEndpoints := kcp.Spec.KubeadmConfigSpec.ClusterConfiguration.Etcd.External.Endpoints
+		if !reflect.DeepEqual(currentEtcdEndpoints, currentKCPEndpoints) {
+			kcp.Spec.KubeadmConfigSpec.ClusterConfiguration.Etcd.External.Endpoints = currentEtcdEndpoints
+			if err := patchHelper.Patch(ctx, kcp); err != nil {
+				log.Error(err, "Failed to patch KubeadmControlPlane to update external etcd endpoints")
+				return ctrl.Result{}, err
+			}
+		}
+	}
 
 	// Initialize the control plane scope; this includes also checking for orphan machines and
 	// adopt them if necessary.
@@ -596,6 +624,21 @@ func (r *KubeadmControlPlaneReconciler) reconcileDelete(ctx context.Context, con
 	log := ctrl.LoggerFrom(ctx)
 	log.Info("Reconcile KubeadmControlPlane deletion")
 
+	// Gets all machines, not just control plane machines.
+	allMachines, err := r.managementCluster.GetMachinesForCluster(ctx, controlPlane.Cluster)
+	if err != nil {
+		return ctrl.Result{}, err
+	}
+
+	if controlPlane.Cluster.Spec.ManagedExternalEtcdRef != nil {
+		for _, machine := range allMachines {
+			if util.IsEtcdMachine(machine) {
+				// remove external etcd-only machines from the "allMachines" collection so that the controlplane machines don't wait for etcd to be deleted first
+				delete(allMachines, machine.Name)
+			}
+		}
+	}
+
 	// If no control plane machines remain, remove the finalizer
 	if len(controlPlane.Machines) == 0 {
 		controlPlane.DeletingReason = controlplanev1.KubeadmControlPlaneDeletingDeletionCompletedV1Beta2Reason
@@ -617,14 +660,6 @@ func (r *KubeadmControlPlaneReconciler) reconcileDelete(ctx context.Context, con
 	// all the machines are deleted in parallel.
 	conditions.SetAggregate(controlPlane.KCP, controlplanev1.MachinesReadyCondition, controlPlane.Machines.ConditionGetters(), conditions.AddSourceRef())
 
-	// Gets all machines, not just control plane machines.
-	allMachines, err := r.managementCluster.GetMachinesForCluster(ctx, controlPlane.Cluster)
-	if err != nil {
-		controlPlane.DeletingReason = controlplanev1.KubeadmControlPlaneDeletingInternalErrorV1Beta2Reason
-		controlPlane.DeletingMessage = "Please check controller logs for errors" //nolint:goconst // Not making this a constant for now
-		return ctrl.Result{}, err
-	}
-
 	allMachinePools := &expv1.MachinePoolList{}
 	// Get all machine pools.
 	if feature.Gates.Enabled(feature.MachinePool) {
diff --git a/internal/apis/core/v1alpha3/cluster_types.go b/internal/apis/core/v1alpha3/cluster_types.go
index 8fd90e134..cb0fb315e 100644
--- a/internal/apis/core/v1alpha3/cluster_types.go
+++ b/internal/apis/core/v1alpha3/cluster_types.go
@@ -55,6 +55,11 @@ type ClusterSpec struct {
 	// +optional
 	ControlPlaneRef *corev1.ObjectReference `json:"controlPlaneRef,omitempty"`
 
+	// ManagedExternalEtcdRef is an optional reference to an etcd provider resource that holds details
+	// for provisioning an external etcd cluster
+	// +optional
+	ManagedExternalEtcdRef *corev1.ObjectReference `json:"managedExternalEtcdRef,omitempty"`
+
 	// infrastructureRef is a reference to a provider-specific resource that holds the details
 	// for provisioning infrastructure for a cluster in said provider.
 	// +optional
@@ -146,6 +151,15 @@ type ClusterStatus struct {
 	// observedGeneration is the latest generation observed by the controller.
 	// +optional
 	ObservedGeneration int64 `json:"observedGeneration,omitempty"`
+
+	// ManagedExternalEtcdInitialized indicates that first etcd member's IP address is set by machine controller,
+	// so remaining etcd members can lookup the address to join the cluster
+	// +optional
+	ManagedExternalEtcdInitialized bool `json:"managedExternalEtcdInitialized"`
+
+	// ManagedExternalEtcdReady indicates external etcd cluster is fully provisioned
+	// +optional
+	ManagedExternalEtcdReady bool `json:"managedExternalEtcdReady"`
 }
 
 // ANCHOR_END: ClusterStatus
diff --git a/internal/apis/core/v1alpha3/condition_consts.go b/internal/apis/core/v1alpha3/condition_consts.go
index 3c0b6195e..c9fd9e27e 100644
--- a/internal/apis/core/v1alpha3/condition_consts.go
+++ b/internal/apis/core/v1alpha3/condition_consts.go
@@ -184,3 +184,19 @@ const (
 	// from making any further remediations.
 	TooManyUnhealthyReason = "TooManyUnhealthy"
 )
+
+// Conditions used by the Etcd provider objects
+const (
+	// ManagedExternalEtcdClusterInitializedCondition is set once the first member of an etcd cluster is provisioned and running
+	ManagedExternalEtcdClusterInitializedCondition ConditionType = "ManagedEtcdInitialized"
+
+	// ManagedExternalEtcdClusterReadyCondition indicates if the etcd cluster is ready and all members have passed healthchecks.
+	ManagedExternalEtcdClusterReadyCondition ConditionType = "ManagedEtcdReady"
+
+	// WaitingForEtcdClusterInitializedReason (Severity=Info) documents a cluster waiting for the etcd cluster
+	// to report successful etcd cluster initialization.
+	WaitingForEtcdClusterInitializedReason = "WaitingForEtcdClusterProviderInitialized"
+
+	// EtcdHealthCheckFailedReason (Severity=Error) documents that healthcheck on an etcd member failed
+	EtcdHealthCheckFailedReason = "EtcdMemberHealthCheckFailed"
+)
diff --git a/internal/apis/core/v1alpha3/conversion.go b/internal/apis/core/v1alpha3/conversion.go
index ae90b8145..7b8dbd913 100644
--- a/internal/apis/core/v1alpha3/conversion.go
+++ b/internal/apis/core/v1alpha3/conversion.go
@@ -39,6 +39,14 @@ func (src *Cluster) ConvertTo(dstRaw conversion.Hub) error {
 		conditions.MarkTrue(dst, clusterv1.ControlPlaneInitializedCondition)
 	}
 
+	if src.Status.ManagedExternalEtcdInitialized {
+		conditions.MarkTrue(dst, clusterv1.ManagedExternalEtcdClusterInitializedCondition)
+	}
+
+	if src.Status.ManagedExternalEtcdReady {
+		conditions.MarkTrue(dst, clusterv1.ManagedExternalEtcdClusterReadyCondition)
+	}
+
 	// Manually restore data.
 	restored := &clusterv1.Cluster{}
 	if ok, err := utilconversion.UnmarshalData(src, restored); err != nil || !ok {
@@ -49,6 +57,11 @@ func (src *Cluster) ConvertTo(dstRaw conversion.Hub) error {
 	if restored.Spec.Topology != nil {
 		dst.Spec.Topology = restored.Spec.Topology
 	}
+
+	if restored.Spec.ManagedExternalEtcdRef != nil {
+		dst.Spec.ManagedExternalEtcdRef = restored.Spec.ManagedExternalEtcdRef
+	}
+
 	dst.Status.V1Beta2 = restored.Status.V1Beta2
 
 	return nil
diff --git a/internal/apis/core/v1alpha3/machine_types.go b/internal/apis/core/v1alpha3/machine_types.go
index 7d0a2324d..db6dcca9b 100644
--- a/internal/apis/core/v1alpha3/machine_types.go
+++ b/internal/apis/core/v1alpha3/machine_types.go
@@ -30,6 +30,9 @@ const (
 	// MachineControlPlaneLabelName is the label set on machines or related objects that are part of a control plane.
 	MachineControlPlaneLabelName = "cluster.x-k8s.io/control-plane"
 
+	//MachineEtcdClusterLabelName is the label set on machines or related objects that are part of an etcd cluster
+	MachineEtcdClusterLabelName = "cluster.x-k8s.io/etcd-cluster"
+
 	// ExcludeNodeDrainingAnnotation annotation explicitly skips node draining if set.
 	ExcludeNodeDrainingAnnotation = "machine.cluster.x-k8s.io/exclude-node-draining"
 
diff --git a/internal/apis/core/v1alpha3/zz_generated.conversion.go b/internal/apis/core/v1alpha3/zz_generated.conversion.go
index 23d631ab5..0ff4d9e53 100644
--- a/internal/apis/core/v1alpha3/zz_generated.conversion.go
+++ b/internal/apis/core/v1alpha3/zz_generated.conversion.go
@@ -510,6 +510,7 @@ func autoConvert_v1alpha3_ClusterSpec_To_v1beta1_ClusterSpec(in *ClusterSpec, ou
 		return err
 	}
 	out.ControlPlaneRef = (*v1.ObjectReference)(unsafe.Pointer(in.ControlPlaneRef))
+	out.ManagedExternalEtcdRef = (*v1.ObjectReference)(unsafe.Pointer(in.ManagedExternalEtcdRef))
 	out.InfrastructureRef = (*v1.ObjectReference)(unsafe.Pointer(in.InfrastructureRef))
 	return nil
 }
@@ -526,6 +527,7 @@ func autoConvert_v1beta1_ClusterSpec_To_v1alpha3_ClusterSpec(in *v1beta1.Cluster
 		return err
 	}
 	out.ControlPlaneRef = (*v1.ObjectReference)(unsafe.Pointer(in.ControlPlaneRef))
+	out.ManagedExternalEtcdRef = (*v1.ObjectReference)(unsafe.Pointer(in.ManagedExternalEtcdRef))
 	out.InfrastructureRef = (*v1.ObjectReference)(unsafe.Pointer(in.InfrastructureRef))
 	// WARNING: in.Topology requires manual conversion: does not exist in peer-type
 	// WARNING: in.AvailabilityGates requires manual conversion: does not exist in peer-type
@@ -542,6 +544,8 @@ func autoConvert_v1alpha3_ClusterStatus_To_v1beta1_ClusterStatus(in *ClusterStat
 	out.ControlPlaneReady = in.ControlPlaneReady
 	out.Conditions = *(*v1beta1.Conditions)(unsafe.Pointer(&in.Conditions))
 	out.ObservedGeneration = in.ObservedGeneration
+	out.ManagedExternalEtcdInitialized = in.ManagedExternalEtcdInitialized
+	out.ManagedExternalEtcdReady = in.ManagedExternalEtcdReady
 	return nil
 }
 
@@ -554,6 +558,8 @@ func autoConvert_v1beta1_ClusterStatus_To_v1alpha3_ClusterStatus(in *v1beta1.Clu
 	out.ControlPlaneReady = in.ControlPlaneReady
 	out.Conditions = *(*Conditions)(unsafe.Pointer(&in.Conditions))
 	out.ObservedGeneration = in.ObservedGeneration
+	out.ManagedExternalEtcdInitialized = in.ManagedExternalEtcdInitialized
+	out.ManagedExternalEtcdReady = in.ManagedExternalEtcdReady
 	// WARNING: in.V1Beta2 requires manual conversion: does not exist in peer-type
 	return nil
 }
diff --git a/internal/apis/core/v1alpha4/cluster_types.go b/internal/apis/core/v1alpha4/cluster_types.go
index 65fdc019a..f3d8206b9 100644
--- a/internal/apis/core/v1alpha4/cluster_types.go
+++ b/internal/apis/core/v1alpha4/cluster_types.go
@@ -56,6 +56,11 @@ type ClusterSpec struct {
 	// +optional
 	ControlPlaneRef *corev1.ObjectReference `json:"controlPlaneRef,omitempty"`
 
+	// ManagedExternalEtcdRef is an optional reference to an etcd provider resource that holds details
+	// for provisioning an external etcd cluster
+	// +optional
+	ManagedExternalEtcdRef *corev1.ObjectReference `json:"managedExternalEtcdRef,omitempty"`
+
 	// infrastructureRef is a reference to a provider-specific resource that holds the details
 	// for provisioning infrastructure for a cluster in said provider.
 	// +optional
@@ -222,6 +227,15 @@ type ClusterStatus struct {
 	// observedGeneration is the latest generation observed by the controller.
 	// +optional
 	ObservedGeneration int64 `json:"observedGeneration,omitempty"`
+
+	// ManagedExternalEtcdInitialized indicates that first etcd member's IP address is set by machine controller,
+	// so remaining etcd members can lookup the address to join the cluster
+	// +optional
+	ManagedExternalEtcdInitialized bool `json:"managedExternalEtcdInitialized"`
+
+	// ManagedExternalEtcdReady indicates external etcd cluster is fully provisioned
+	// +optional
+	ManagedExternalEtcdReady bool `json:"managedExternalEtcdReady"`
 }
 
 // ANCHOR_END: ClusterStatus
diff --git a/internal/apis/core/v1alpha4/condition_consts.go b/internal/apis/core/v1alpha4/condition_consts.go
index d3c84b66d..317d6cad5 100644
--- a/internal/apis/core/v1alpha4/condition_consts.go
+++ b/internal/apis/core/v1alpha4/condition_consts.go
@@ -251,3 +251,19 @@ const (
 	// ScalingDownReason (Severity=Info) documents a MachineSet is decreasing the number of replicas.
 	ScalingDownReason = "ScalingDown"
 )
+
+// Conditions used by the Etcd provider objects
+const (
+	// ManagedExternalEtcdClusterInitializedCondition is set once the first member of an etcd cluster is provisioned and running
+	ManagedExternalEtcdClusterInitializedCondition ConditionType = "ManagedEtcdInitialized"
+
+	// ManagedExternalEtcdClusterReadyCondition indicates if the etcd cluster is ready and all members have passed healthchecks.
+	ManagedExternalEtcdClusterReadyCondition ConditionType = "ManagedEtcdReady"
+
+	// WaitingForEtcdClusterInitializedReason (Severity=Info) documents a cluster waiting for the etcd cluster
+	// to report successful etcd cluster initialization.
+	WaitingForEtcdClusterInitializedReason = "WaitingForEtcdClusterProviderInitialized"
+
+	// EtcdHealthCheckFailedReason (Severity=Error) documents that healthcheck on an etcd member failed
+	EtcdHealthCheckFailedReason = "EtcdMemberHealthCheckFailed"
+)
diff --git a/internal/apis/core/v1alpha4/machine_types.go b/internal/apis/core/v1alpha4/machine_types.go
index ef74d2c71..16259e47b 100644
--- a/internal/apis/core/v1alpha4/machine_types.go
+++ b/internal/apis/core/v1alpha4/machine_types.go
@@ -30,6 +30,9 @@ const (
 	// MachineControlPlaneLabelName is the label set on machines or related objects that are part of a control plane.
 	MachineControlPlaneLabelName = "cluster.x-k8s.io/control-plane"
 
+	//MachineEtcdClusterLabelName is the label set on machines or related objects that are part of an etcd cluster
+	MachineEtcdClusterLabelName = "cluster.x-k8s.io/etcd-cluster"
+
 	// ExcludeNodeDrainingAnnotation annotation explicitly skips node draining if set.
 	ExcludeNodeDrainingAnnotation = "machine.cluster.x-k8s.io/exclude-node-draining"
 
diff --git a/internal/apis/core/v1alpha4/zz_generated.conversion.go b/internal/apis/core/v1alpha4/zz_generated.conversion.go
index 14df0dfc9..3a401477e 100644
--- a/internal/apis/core/v1alpha4/zz_generated.conversion.go
+++ b/internal/apis/core/v1alpha4/zz_generated.conversion.go
@@ -731,6 +731,7 @@ func autoConvert_v1alpha4_ClusterSpec_To_v1beta1_ClusterSpec(in *ClusterSpec, ou
 		return err
 	}
 	out.ControlPlaneRef = (*v1.ObjectReference)(unsafe.Pointer(in.ControlPlaneRef))
+	out.ManagedExternalEtcdRef = (*v1.ObjectReference)(unsafe.Pointer(in.ManagedExternalEtcdRef))
 	out.InfrastructureRef = (*v1.ObjectReference)(unsafe.Pointer(in.InfrastructureRef))
 	if in.Topology != nil {
 		in, out := &in.Topology, &out.Topology
@@ -756,6 +757,7 @@ func autoConvert_v1beta1_ClusterSpec_To_v1alpha4_ClusterSpec(in *v1beta1.Cluster
 		return err
 	}
 	out.ControlPlaneRef = (*v1.ObjectReference)(unsafe.Pointer(in.ControlPlaneRef))
+	out.ManagedExternalEtcdRef = (*v1.ObjectReference)(unsafe.Pointer(in.ManagedExternalEtcdRef))
 	out.InfrastructureRef = (*v1.ObjectReference)(unsafe.Pointer(in.InfrastructureRef))
 	if in.Topology != nil {
 		in, out := &in.Topology, &out.Topology
@@ -779,6 +781,8 @@ func autoConvert_v1alpha4_ClusterStatus_To_v1beta1_ClusterStatus(in *ClusterStat
 	out.ControlPlaneReady = in.ControlPlaneReady
 	out.Conditions = *(*v1beta1.Conditions)(unsafe.Pointer(&in.Conditions))
 	out.ObservedGeneration = in.ObservedGeneration
+	out.ManagedExternalEtcdInitialized = in.ManagedExternalEtcdInitialized
+	out.ManagedExternalEtcdReady = in.ManagedExternalEtcdReady
 	return nil
 }
 
@@ -796,6 +800,8 @@ func autoConvert_v1beta1_ClusterStatus_To_v1alpha4_ClusterStatus(in *v1beta1.Clu
 	out.ControlPlaneReady = in.ControlPlaneReady
 	out.Conditions = *(*Conditions)(unsafe.Pointer(&in.Conditions))
 	out.ObservedGeneration = in.ObservedGeneration
+	out.ManagedExternalEtcdInitialized = in.ManagedExternalEtcdInitialized
+	out.ManagedExternalEtcdReady = in.ManagedExternalEtcdReady
 	// WARNING: in.V1Beta2 requires manual conversion: does not exist in peer-type
 	return nil
 }
diff --git a/internal/controllers/cluster/cluster_controller.go b/internal/controllers/cluster/cluster_controller.go
index a0a9d5542..279e8cdd8 100644
--- a/internal/controllers/cluster/cluster_controller.go
+++ b/internal/controllers/cluster/cluster_controller.go
@@ -19,6 +19,7 @@ package cluster
 import (
 	"context"
 	"fmt"
+	"path"
 	"sort"
 	"strings"
 	"time"
@@ -71,7 +72,7 @@ const (
 //
 // +kubebuilder:rbac:groups=core,resources=events,verbs=create;patch
 // +kubebuilder:rbac:groups=core,resources=secrets,verbs=get;list;watch;create;patch;update
-// +kubebuilder:rbac:groups=infrastructure.cluster.x-k8s.io;bootstrap.cluster.x-k8s.io;controlplane.cluster.x-k8s.io,resources=*,verbs=get;list;watch;create;update;patch;delete
+// +kubebuilder:rbac:groups=infrastructure.cluster.x-k8s.io;bootstrap.cluster.x-k8s.io;controlplane.cluster.x-k8s.io;etcdcluster.cluster.x-k8s.io,resources=*,verbs=get;list;watch;create;update;patch;delete
 // +kubebuilder:rbac:groups=cluster.x-k8s.io,resources=clusters;clusters/status;clusters/finalizers,verbs=get;list;watch;update;patch
 // +kubebuilder:rbac:groups=apiextensions.k8s.io,resources=customresourcedefinitions,verbs=get;list;watch
 
@@ -106,6 +107,11 @@ func (r *Reconciler) SetupWithManager(ctx context.Context, mgr ctrl.Manager, opt
 			handler.EnqueueRequestsFromMapFunc(r.controlPlaneMachineToCluster),
 			builder.WithPredicates(predicates.ResourceIsChanged(mgr.GetScheme(), predicateLog)),
 		).
+		Watches(
+			&clusterv1.Machine{},
+			handler.EnqueueRequestsFromMapFunc(r.etcdMachineToCluster),
+			builder.WithPredicates(predicates.ResourceIsChanged(mgr.GetScheme(), predicateLog)),
+		).
 		Watches(
 			&clusterv1.MachineDeployment{},
 			handler.EnqueueRequestsFromMapFunc(r.machineDeploymentToCluster),
@@ -239,6 +245,7 @@ func (r *Reconciler) Reconcile(ctx context.Context, req ctrl.Request) (retRes ct
 		alwaysReconcile,
 		r.reconcileKubeconfig,
 		r.reconcileControlPlaneInitialized,
+		r.reconcileEtcdCluster,
 	)
 	return doReconcile(ctx, reconcileNormal, s)
 }
@@ -249,6 +256,7 @@ func patchCluster(ctx context.Context, patchHelper *patch.Helper, cluster *clust
 		conditions.WithConditions(
 			clusterv1.ControlPlaneReadyCondition,
 			clusterv1.InfrastructureReadyCondition,
+			clusterv1.ManagedExternalEtcdClusterReadyCondition,
 		),
 	)
 
@@ -260,6 +268,7 @@ func patchCluster(ctx context.Context, patchHelper *patch.Helper, cluster *clust
 			clusterv1.ReadyCondition,
 			clusterv1.ControlPlaneReadyCondition,
 			clusterv1.InfrastructureReadyCondition,
+			clusterv1.ManagedExternalEtcdClusterReadyCondition,
 		}},
 		patch.WithOwnedV1Beta2Conditions{Conditions: []string{
 			clusterv1.ClusterInfrastructureReadyV1Beta2Condition,
@@ -454,6 +463,36 @@ func (r *Reconciler) reconcileDelete(ctx context.Context, s *scope) (reconcile.R
 			return ctrl.Result{}, nil
 		}
 	}
+	if cluster.Spec.ManagedExternalEtcdRef != nil {
+		obj, err := external.Get(ctx, r.Client, cluster.Spec.ManagedExternalEtcdRef, cluster.Namespace)
+		switch {
+		case apierrors.IsNotFound(errors.Cause(err)):
+			// Etcd cluster has been deleted
+			conditions.MarkFalse(cluster, clusterv1.ManagedExternalEtcdClusterReadyCondition, clusterv1.DeletedReason, clusterv1.ConditionSeverityInfo, "")
+		case err != nil:
+			return ctrl.Result{}, errors.Wrapf(err, "failed to get %s %q for Cluster %s/%s",
+				path.Join(cluster.Spec.ManagedExternalEtcdRef.APIVersion, cluster.Spec.ManagedExternalEtcdRef.Kind),
+				cluster.Spec.ManagedExternalEtcdRef.Name, cluster.Namespace, cluster.Name)
+		default:
+			// Report a summary of current status of the external etcd object defined for this cluster.
+			conditions.SetMirror(cluster, clusterv1.ManagedExternalEtcdClusterReadyCondition,
+				conditions.UnstructuredGetter(obj),
+				conditions.WithFallbackValue(false, clusterv1.DeletingReason, clusterv1.ConditionSeverityInfo, ""),
+			)
+
+			// Issue a deletion request for the infrastructure object.
+			// Once it's been deleted, the cluster will get processed again.
+			if err := r.Client.Delete(ctx, obj); err != nil {
+				return ctrl.Result{}, errors.Wrapf(err,
+					"failed to delete %v %q for Cluster %q in namespace %q",
+					obj.GroupVersionKind(), obj.GetName(), cluster.Name, cluster.Namespace)
+			}
+
+			// Return here so we don't remove the finalizer yet.
+			log.Info("Cluster still has descendants - need to requeue", "managedExternalEtcdRef", cluster.Spec.ManagedExternalEtcdRef.Name)
+			return ctrl.Result{}, nil
+		}
+	}
 
 	if cluster.Spec.InfrastructureRef != nil {
 		if s.infraCluster == nil {
@@ -510,6 +549,7 @@ type clusterDescendants struct {
 	machinesToBeRemediated collections.Machines
 	unhealthyMachines      collections.Machines
 	machinePools           expv1.MachinePoolList
+	etcdMachines           collections.Machines
 }
 
 // objectsPendingDeleteCount returns the number of descendants pending delete.
@@ -541,6 +581,13 @@ func (c *clusterDescendants) objectsPendingDeleteNames(cluster *clusterv1.Cluste
 			descendants = append(descendants, "Control plane Machines: "+clog.StringListToString(controlPlaneMachineNames))
 		}
 	}
+	etcdMachines := make([]string, len(collections.ToMachineList(c.etcdMachines).Items))
+	for i, etcdMachine := range collections.ToMachineList(c.etcdMachines).Items {
+		etcdMachines[i] = etcdMachine.Name
+	}
+	if len(etcdMachines) > 0 {
+		descendants = append(descendants, "Etcd machines: "+strings.Join(etcdMachines, ","))
+	}
 	machineDeploymentNames := make([]string, len(c.machineDeployments.Items))
 	for i, machineDeployment := range c.machineDeployments.Items {
 		machineDeploymentNames[i] = machineDeployment.Name
@@ -609,7 +656,8 @@ func (r *Reconciler) getDescendants(ctx context.Context, s *scope) (reconcile.Re
 	// Split machines into control plane and worker machines
 	descendants.allMachines = collections.FromMachineList(&machines)
 	descendants.controlPlaneMachines = descendants.allMachines.Filter(collections.ControlPlaneMachines(cluster.Name))
-	descendants.workerMachines = descendants.allMachines.Difference(descendants.controlPlaneMachines)
+	descendants.etcdMachines = descendants.allMachines.Filter(collections.EtcdMachines(cluster.Name))
+	descendants.workerMachines = descendants.allMachines.Difference(descendants.controlPlaneMachines).Difference(descendants.etcdMachines)
 	descendants.machinesToBeRemediated = descendants.allMachines.Filter(collections.IsUnhealthyAndOwnerRemediated)
 	descendants.unhealthyMachines = descendants.allMachines.Filter(collections.IsUnhealthy)
 
@@ -655,6 +703,9 @@ func (c *clusterDescendants) filterOwnedDescendants(cluster *clusterv1.Cluster)
 		&c.machineSets,
 		toObjectList(c.workerMachines),
 	}
+	if cluster.Spec.ManagedExternalEtcdRef != nil {
+		lists = append(lists, &c.etcdMachines)
+	}
 	if feature.Gates.Enabled(feature.MachinePool) {
 		lists = append([]client.ObjectList{&c.machinePools}, lists...)
 	}
@@ -745,6 +796,36 @@ func (r *Reconciler) controlPlaneMachineToCluster(ctx context.Context, o client.
 	}}
 }
 
+// etcdMachineToCluster is a handler.ToRequestsFunc to be used to enqueue requests for reconciliation
+// for Cluster to update its status.ManagedExternalEtcdInitialized field
+func (r *Reconciler) etcdMachineToCluster(ctx context.Context, o client.Object) []ctrl.Request {
+	m, ok := o.(*clusterv1.Machine)
+	if !ok {
+		panic(fmt.Sprintf("Expected a Machine but got a %T", o))
+	}
+	if !util.IsEtcdMachine(m) {
+		return nil
+	}
+	// address has not been set, so ManagedExternalEtcdInitialized would not be true
+	if len(m.Status.Addresses) == 0 {
+		return nil
+	}
+
+	cluster, err := util.GetClusterByName(context.TODO(), r.Client, m.Namespace, m.Spec.ClusterName)
+	if err != nil {
+		return nil
+	}
+
+	if cluster.Status.ManagedExternalEtcdInitialized {
+		// no need to enqueue cluster for reconcile based on machine changes
+		return nil
+	}
+
+	return []ctrl.Request{{
+		NamespacedName: util.ObjectKey(cluster),
+	}}
+}
+
 // machineDeploymentToCluster is a handler.ToRequestsFunc to be used to enqueue requests for reconciliation
 // for Cluster to update when one of its own MachineDeployments gets updated.
 func (r *Reconciler) machineDeploymentToCluster(_ context.Context, o client.Object) []ctrl.Request {
diff --git a/internal/controllers/cluster/cluster_controller_phases.go b/internal/controllers/cluster/cluster_controller_phases.go
index 31329659f..f2ac66160 100644
--- a/internal/controllers/cluster/cluster_controller_phases.go
+++ b/internal/controllers/cluster/cluster_controller_phases.go
@@ -37,6 +37,7 @@ import (
 	"sigs.k8s.io/cluster-api/controllers/external"
 	capierrors "sigs.k8s.io/cluster-api/errors"
 	"sigs.k8s.io/cluster-api/util"
+	"sigs.k8s.io/cluster-api/util/annotations"
 	"sigs.k8s.io/cluster-api/util/conditions"
 	utilconversion "sigs.k8s.io/cluster-api/util/conversion"
 	"sigs.k8s.io/cluster-api/util/kubeconfig"
@@ -260,6 +261,39 @@ func (r *Reconciler) reconcileControlPlane(ctx context.Context, s *scope) (ctrl.
 		return ctrl.Result{}, nil
 	}
 
+	if cluster.Spec.ManagedExternalEtcdRef != nil {
+		// check if the referenced etcd cluster is ready or not
+		etcdRef := cluster.Spec.ManagedExternalEtcdRef
+		externalEtcd, err := external.Get(ctx, r.Client, etcdRef)
+		if err != nil {
+			if apierrors.IsNotFound(errors.Cause(err)) {
+				log.Info("Could not find external object for cluster, requeuing", "refGroupVersionKind", etcdRef.GroupVersionKind(), "refName", etcdRef.Name)
+				return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
+			}
+			return ctrl.Result{}, err
+		}
+		externalEtcdReady, err := external.IsReady(externalEtcd)
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+		if !externalEtcdReady {
+			// External Etcd Cluster has not been created, pause control plane provisioning by setting the paused annotation on the Control plane object
+			controlPlane, err := external.Get(ctx, r.Client, cluster.Spec.ControlPlaneRef)
+			if err != nil {
+				if apierrors.IsNotFound(errors.Cause(err)) {
+					log.Info("Could not find control plane for cluster, requeuing", "refGroupVersionKind", cluster.Spec.ControlPlaneRef.GroupVersionKind(), "refName", cluster.Spec.ControlPlaneRef.Name)
+					return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
+				}
+				return ctrl.Result{}, err
+			}
+			annotations.AddAnnotations(controlPlane, map[string]string{clusterv1.PausedAnnotation: "true"})
+			if err := r.Client.Update(ctx, controlPlane, &client.UpdateOptions{}); err != nil {
+				log.Error(err, "error pausing control plane")
+				return ctrl.Result{Requeue: true}, err
+			}
+		}
+	}
+
 	// Call generic external reconciler.
 	obj, err := r.reconcileExternal(ctx, cluster, cluster.Spec.ControlPlaneRef)
 	if err != nil {
@@ -343,6 +377,77 @@ func (r *Reconciler) reconcileControlPlane(ctx context.Context, s *scope) (ctrl.
 	return ctrl.Result{}, nil
 }
 
+func (r *Reconciler) reconcileEtcdCluster(ctx context.Context, cluster *clusterv1.Cluster) (ctrl.Result, error) {
+	log := ctrl.LoggerFrom(ctx)
+
+	if cluster.Spec.ManagedExternalEtcdRef == nil {
+		return ctrl.Result{}, nil
+	}
+	// Call generic external reconciler.
+	obj, err := r.reconcileExternal(ctx, cluster, cluster.Spec.ManagedExternalEtcdRef)
+	etcdPlaneReconcileResult := external.ReconcileOutput{Result: obj}
+	if err != nil {
+		return ctrl.Result{}, err
+	}
+	// Return early if we need to requeue.
+	if etcdPlaneReconcileResult.RequeueAfter > 0 {
+		return ctrl.Result{RequeueAfter: etcdPlaneReconcileResult.RequeueAfter}, nil
+	}
+
+	etcdPlaneConfig := etcdPlaneReconcileResult.Result
+
+	// There's no need to go any further if the etcd cluster resource is marked for deletion.
+	if !etcdPlaneConfig.GetDeletionTimestamp().IsZero() {
+		return ctrl.Result{}, nil
+	}
+
+	// Determine if the etcd cluster is ready.
+	ready, err := external.IsReady(etcdPlaneConfig)
+	if err != nil {
+		return ctrl.Result{}, err
+	}
+	cluster.Status.ManagedExternalEtcdReady = ready
+
+	if ready {
+		// resume control plane
+		controlPlane, err := external.Get(ctx, r.Client, cluster.Spec.ControlPlaneRef)
+		if err != nil {
+			if apierrors.IsNotFound(errors.Cause(err)) {
+				log.Info("Could not find control plane for cluster, requeuing", "refGroupVersionKind", cluster.Spec.ControlPlaneRef.GroupVersionKind(), "refName", cluster.Spec.ControlPlaneRef.Name)
+				return ctrl.Result{RequeueAfter: 30 * time.Second}, nil
+			}
+			return ctrl.Result{}, err
+		}
+		unstructured.RemoveNestedField(controlPlane.Object, "metadata", "annotations", clusterv1.PausedAnnotation)
+		if err := r.Client.Update(ctx, controlPlane, &client.UpdateOptions{}); err != nil {
+			log.Error(err, "error resuming control plane")
+			return ctrl.Result{Requeue: true}, err
+		}
+	}
+
+	// Report a summary of current status of the etcd cluster object defined for this cluster.
+	conditions.SetMirror(cluster, clusterv1.ManagedExternalEtcdClusterReadyCondition,
+		conditions.UnstructuredGetter(etcdPlaneConfig),
+		conditions.WithFallbackValue(ready, clusterv1.WaitingForEtcdClusterInitializedReason, clusterv1.ConditionSeverityInfo, ""),
+	)
+
+	// Update cluster.Status.ManagedExternalEtcdClusterInitializedCondition if it hasn't already been set
+	if !conditions.IsTrue(cluster, clusterv1.ManagedExternalEtcdClusterInitializedCondition) {
+		initialized, err := external.IsInitialized(etcdPlaneConfig)
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+		if initialized {
+			log.Info("reconcileEtcdCluster: Marking etcd cluster initialized setting it to true")
+			cluster.Status.ManagedExternalEtcdInitialized = true
+			conditions.MarkTrue(cluster, clusterv1.ManagedExternalEtcdClusterInitializedCondition)
+		} else {
+			conditions.MarkFalse(cluster, clusterv1.ManagedExternalEtcdClusterInitializedCondition, clusterv1.WaitingForEtcdClusterInitializedReason, clusterv1.ConditionSeverityInfo, "Waiting for etcd cluster provider to indicate the etcd has been initialized")
+		}
+	}
+	return ctrl.Result{}, nil
+}
+
 func (r *Reconciler) reconcileKubeconfig(ctx context.Context, s *scope) (ctrl.Result, error) {
 	log := ctrl.LoggerFrom(ctx)
 	cluster := s.cluster
diff --git a/internal/controllers/cluster/cluster_controller_test.go b/internal/controllers/cluster/cluster_controller_test.go
index 612b31d0b..00df217cb 100644
--- a/internal/controllers/cluster/cluster_controller_test.go
+++ b/internal/controllers/cluster/cluster_controller_test.go
@@ -610,6 +610,124 @@ func TestClusterReconcilerNodeRef(t *testing.T) {
 	})
 }
 
+func TestClusterReconcilerEtcdMachineToCluster(t *testing.T) {
+	t.Run("machine to cluster", func(t *testing.T) {
+		clusterEtcdNotInitialized := &clusterv1.Cluster{
+			TypeMeta: metav1.TypeMeta{
+				Kind: "Cluster",
+			},
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      "test-cluster",
+				Namespace: "test",
+			},
+			Spec:   clusterv1.ClusterSpec{},
+			Status: clusterv1.ClusterStatus{},
+		}
+		clusterEtcdInitialized := &clusterv1.Cluster{
+			TypeMeta: metav1.TypeMeta{
+				Kind: "Cluster",
+			},
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      "test-cluster-etcd-init",
+				Namespace: "test",
+			},
+			Spec:   clusterv1.ClusterSpec{},
+			Status: clusterv1.ClusterStatus{ManagedExternalEtcdInitialized: true},
+		}
+		etcdMachineWithAddress := &clusterv1.Machine{
+			TypeMeta: metav1.TypeMeta{
+				Kind: "Machine",
+			},
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      "etcdWithAddress",
+				Namespace: "test",
+				Labels: map[string]string{
+					clusterv1.ClusterNameLabel:            clusterEtcdNotInitialized.Name,
+					clusterv1.MachineEtcdClusterLabelName: "",
+				},
+			},
+			Spec: clusterv1.MachineSpec{
+				ClusterName: "test-cluster",
+			},
+			Status: clusterv1.MachineStatus{
+				Addresses: clusterv1.MachineAddresses{clusterv1.MachineAddress{Type: clusterv1.MachineExternalIP, Address: "test"}},
+			},
+		}
+		etcdMachineNoAddress := &clusterv1.Machine{
+			TypeMeta: metav1.TypeMeta{
+				Kind: "Machine",
+			},
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      "etcdNoAddress",
+				Namespace: "test",
+				Labels: map[string]string{
+					clusterv1.ClusterNameLabel:            clusterEtcdNotInitialized.Name,
+					clusterv1.MachineEtcdClusterLabelName: "",
+				},
+			},
+			Spec: clusterv1.MachineSpec{
+				ClusterName: "test-cluster",
+			},
+			Status: clusterv1.MachineStatus{},
+		}
+		etcdMachineNoAddressForInitializedCluster := &clusterv1.Machine{
+			TypeMeta: metav1.TypeMeta{
+				Kind: "Machine",
+			},
+			ObjectMeta: metav1.ObjectMeta{
+				Name:      "etcdNoAddressClusterEtcdInitialized",
+				Namespace: "test",
+				Labels: map[string]string{
+					clusterv1.ClusterNameLabel:            clusterEtcdInitialized.Name,
+					clusterv1.MachineEtcdClusterLabelName: "",
+				},
+			},
+			Spec: clusterv1.MachineSpec{
+				ClusterName: "test-cluster-etcd-init",
+			},
+			Status: clusterv1.MachineStatus{},
+		}
+
+		tests := []struct {
+			name string
+			o    client.Object
+			want []ctrl.Request
+		}{
+			{
+				name: "etcd machine, address is set, should return cluster",
+				o:    etcdMachineWithAddress,
+				want: []ctrl.Request{
+					{
+						NamespacedName: util.ObjectKey(clusterEtcdNotInitialized),
+					},
+				},
+			},
+			{
+				name: "etcd machine, address is not set, should not return cluster",
+				o:    etcdMachineNoAddress,
+				want: nil,
+			},
+			{
+				name: "etcd machine, address is not set, but etcd is initialized, should not return cluster",
+				o:    etcdMachineNoAddressForInitializedCluster,
+				want: nil,
+			},
+		}
+		for _, tt := range tests {
+			t.Run(tt.name, func(t *testing.T) {
+				g := NewWithT(t)
+
+				r := &Reconciler{
+					Client: fake.NewClientBuilder().WithObjects(clusterEtcdNotInitialized, clusterEtcdInitialized, etcdMachineNoAddress, etcdMachineWithAddress, etcdMachineNoAddressForInitializedCluster).Build(),
+				}
+
+				requests := r.etcdMachineToCluster(ctx, tt.o)
+				g.Expect(requests).To(Equal(tt.want))
+			})
+		}
+	})
+}
+
 type machineDeploymentBuilder struct {
 	md clusterv1.MachineDeployment
 }
@@ -689,6 +807,11 @@ func (b *machineBuilder) controlPlane() *machineBuilder {
 	return b
 }
 
+func (b *machineBuilder) etcd() *machineBuilder {
+	b.m.Labels = map[string]string{clusterv1.MachineEtcdClusterLabelName: ""}
+	return b
+}
+
 func (b *machineBuilder) build() clusterv1.Machine {
 	return b.m
 }
@@ -730,6 +853,9 @@ func TestFilterOwnedDescendants(t *testing.T) {
 		ObjectMeta: metav1.ObjectMeta{
 			Name: "c",
 		},
+		Spec: clusterv1.ClusterSpec{
+			ManagedExternalEtcdRef: &corev1.ObjectReference{},
+		},
 	}
 
 	md1NotOwnedByCluster := newMachineDeploymentBuilder().named("md1").build()
@@ -754,6 +880,9 @@ func TestFilterOwnedDescendants(t *testing.T) {
 	mp3NotOwnedByCluster := newMachinePoolBuilder().named("mp3").build()
 	mp4OwnedByCluster := newMachinePoolBuilder().named("mp4").ownedBy(&c).build()
 
+	me1EtcdOwnedByCluster := newMachineBuilder().named("me1").ownedBy(&c).etcd().build()
+	me2EtcdNotOwnedByCluster := newMachineBuilder().named("me2").build()
+
 	d := clusterDescendants{
 		machineDeployments: clusterv1.MachineDeploymentList{
 			Items: []clusterv1.MachineDeployment{
@@ -793,6 +922,12 @@ func TestFilterOwnedDescendants(t *testing.T) {
 				mp4OwnedByCluster,
 			},
 		},
+		etcdMachines: collections.FromMachineList(&clusterv1.MachineList{
+			Items: []clusterv1.Machine{
+				me1EtcdOwnedByCluster,
+				me2EtcdNotOwnedByCluster,
+			},
+		}),
 	}
 
 	t.Run("Without a control plane object", func(t *testing.T) {
@@ -812,6 +947,7 @@ func TestFilterOwnedDescendants(t *testing.T) {
 			&m5OwnedByCluster,
 			&m3ControlPlaneOwnedByCluster,
 			&m6ControlPlaneOwnedByCluster,
+			&me1EtcdOwnedByCluster,
 		))
 	})
 
diff --git a/internal/controllers/machine/machine_controller_noderef.go b/internal/controllers/machine/machine_controller_noderef.go
index 683468242..05a94cc27 100644
--- a/internal/controllers/machine/machine_controller_noderef.go
+++ b/internal/controllers/machine/machine_controller_noderef.go
@@ -57,6 +57,14 @@ func (r *Reconciler) reconcileNode(ctx context.Context, s *scope) (ctrl.Result,
 		return ctrl.Result{}, err
 	}
 
+	if _, ok := machine.Labels[clusterv1.MachineEtcdClusterLabelName]; ok {
+		// Etcd member Machines do not correspond to Kubernetes v1 Nodes; cannot get k8s node to set nodeRef
+		// This prevents the MachineNodeHealthyCondition from being set in etcd machines, neither true nor false.
+		// It makes sense since etcd machines are not kubernetes nodes and it doesn't present any issues since the
+		// summary ready condition doesn't depend on it.
+		return ctrl.Result{}, nil
+	}
+
 	// Check that the Machine has a valid ProviderID.
 	if machine.Spec.ProviderID == nil || *machine.Spec.ProviderID == "" {
 		log.Info("Waiting for infrastructure provider to report spec.providerID", machine.Spec.InfrastructureRef.Kind, klog.KRef(machine.Spec.InfrastructureRef.Namespace, machine.Spec.InfrastructureRef.Name))
diff --git a/internal/controllers/machine/machine_controller_noderef_test.go b/internal/controllers/machine/machine_controller_noderef_test.go
index ef56f947e..766a60a5e 100644
--- a/internal/controllers/machine/machine_controller_noderef_test.go
+++ b/internal/controllers/machine/machine_controller_noderef_test.go
@@ -27,6 +27,7 @@ import (
 	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 	"k8s.io/apimachinery/pkg/apis/meta/v1/unstructured"
 	"k8s.io/client-go/tools/record"
+	"k8s.io/utils/pointer"
 	"k8s.io/utils/ptr"
 	ctrl "sigs.k8s.io/controller-runtime"
 	"sigs.k8s.io/controller-runtime/pkg/client"
@@ -41,6 +42,7 @@ import (
 	"sigs.k8s.io/cluster-api/controllers/remote"
 	"sigs.k8s.io/cluster-api/internal/topology/ownerrefs"
 	"sigs.k8s.io/cluster-api/util"
+	"sigs.k8s.io/cluster-api/util/conditions"
 	"sigs.k8s.io/cluster-api/util/kubeconfig"
 	"sigs.k8s.io/cluster-api/util/test/builder"
 )
@@ -1362,3 +1364,47 @@ func Test_shouldNodeHaveOutdatedTaint(t *testing.T) {
 		})
 	}
 }
+
+func TestReconcileNodeForEtcdMachines(t *testing.T) {
+	testCases := []struct {
+		name    string
+		machine *clusterv1.Machine
+	}{
+		{
+			name: "with providerID",
+			machine: &clusterv1.Machine{
+				ObjectMeta: metav1.ObjectMeta{
+					Labels: map[string]string{
+						clusterv1.MachineEtcdClusterLabelName: "true",
+					},
+				},
+				Spec: clusterv1.MachineSpec{
+					ProviderID: pointer.String("ID"),
+				},
+			},
+		},
+		{
+			name: "without providerID",
+			machine: &clusterv1.Machine{
+				ObjectMeta: metav1.ObjectMeta{
+					Labels: map[string]string{
+						clusterv1.MachineEtcdClusterLabelName: "true",
+					},
+				},
+				Spec: clusterv1.MachineSpec{},
+			},
+		},
+	}
+	for _, tc := range testCases {
+		t.Run(tc.name, func(t *testing.T) {
+			g := NewWithT(t)
+			r := Reconciler{Client: env}
+			s := &scope{
+				cluster: &clusterv1.Cluster{},
+				machine: tc.machine,
+			}
+			g.Expect(r.reconcileNode(ctx, s)).To(Equal(ctrl.Result{}))
+			g.Expect(conditions.Get(tc.machine, clusterv1.MachineNodeHealthyCondition)).To(BeNil())
+		})
+	}
+}
diff --git a/internal/controllers/machine/machine_controller_phases.go b/internal/controllers/machine/machine_controller_phases.go
index 88925e279..43dfa579b 100644
--- a/internal/controllers/machine/machine_controller_phases.go
+++ b/internal/controllers/machine/machine_controller_phases.go
@@ -21,6 +21,8 @@ import (
 	"fmt"
 	"time"
 
+	"sigs.k8s.io/controller-runtime/pkg/client"
+
 	"github.com/pkg/errors"
 	corev1 "k8s.io/api/core/v1"
 	apierrors "k8s.io/apimachinery/pkg/api/errors"
@@ -296,6 +298,121 @@ func (r *Reconciler) reconcileInfrastructure(ctx context.Context, s *scope) (ctr
 		return ctrl.Result{}, errors.Wrapf(err, "failed to retrieve addresses from infrastructure provider for Machine %q in namespace %q", m.Name, m.Namespace)
 	}
 
+	if cluster.Spec.ManagedExternalEtcdRef != nil {
+		// set first node's IP address on EtcdCluster
+		// get etcd cluster
+		ref := cluster.Spec.ManagedExternalEtcdRef
+		obj, err := external.Get(ctx, r.Client, ref)
+		if err != nil {
+			if apierrors.IsNotFound(errors.Cause(err)) {
+				return ctrl.Result{}, err
+			}
+			return ctrl.Result{}, err
+		}
+		// Initialize the patch helper.
+		patchHelper, err := patch.NewHelper(obj, r.Client)
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+		address, addressSet, err := unstructured.NestedFieldNoCopy(obj.Object, "status", "initMachineAddress")
+		if err != nil {
+			return ctrl.Result{}, err
+		}
+
+		if !addressSet || address == "" {
+			etcdSecretName := fmt.Sprintf("%v-%v", cluster.Name, "etcd-init")
+			existingSecret := &corev1.Secret{}
+			if err := r.Client.Get(ctx, client.ObjectKey{Namespace: cluster.Namespace, Name: etcdSecretName}, existingSecret); err != nil {
+				if apierrors.IsNotFound(err) {
+					// secret doesn't exist, so create it for the init machine
+					var internalIP, internalDNS, externalIP, externalDNS, machineIP string
+					for _, address := range m.Status.Addresses {
+						switch address.Type {
+						case clusterv1.MachineInternalIP:
+							internalIP = address.Address
+						case clusterv1.MachineInternalDNS:
+							internalDNS = address.Address
+						case clusterv1.MachineExternalIP:
+							externalIP = address.Address
+						case clusterv1.MachineExternalDNS:
+							externalDNS = address.Address
+						}
+					}
+
+					// The order of these checks determines the precedence of the address to use
+					if externalDNS != "" {
+						machineIP = externalDNS
+					} else if externalIP != "" {
+						machineIP = externalIP
+					} else if internalDNS != "" {
+						machineIP = internalDNS
+					} else if internalIP != "" {
+						machineIP = internalIP
+					}
+
+					if machineIP == "" {
+						return ctrl.Result{}, fmt.Errorf("error getting etcd init IP address: %v", err)
+					}
+
+					secret := &corev1.Secret{
+						ObjectMeta: metav1.ObjectMeta{
+							Name:      etcdSecretName,
+							Namespace: cluster.Namespace,
+							Labels: map[string]string{
+								clusterv1.ClusterNameLabel: cluster.Name,
+							},
+							OwnerReferences: []metav1.OwnerReference{
+								{
+									APIVersion: clusterv1.GroupVersion.String(),
+									Kind:       cluster.Kind,
+									Name:       cluster.Name,
+									UID:        cluster.UID,
+								},
+							},
+						},
+						Data: map[string][]byte{
+							"address": []byte(machineIP),
+						},
+						Type: clusterv1.ClusterSecretType,
+					}
+					if err := r.Client.Create(ctx, secret); err != nil && !apierrors.IsAlreadyExists(err) {
+						return ctrl.Result{}, err
+					}
+
+					// set the Secret name on etcdCluster and update it so it receives a sync
+					if err := unstructured.SetNestedField(obj.Object, etcdSecretName, "status", "initMachineAddress"); err != nil {
+						return ctrl.Result{}, err
+					}
+					// set Initialized to true on etcdCluster and update it so it receives a sync
+					if err := unstructured.SetNestedField(obj.Object, true, "status", "initialized"); err != nil {
+						return ctrl.Result{}, err
+					}
+					// Always attempt to Patch the external object.
+					if err := patchHelper.Patch(ctx, obj); err != nil {
+						return ctrl.Result{}, err
+					}
+				} else {
+					log.Error(err, "error getting etcd init secret containing address")
+					return ctrl.Result{}, err
+				}
+			} else {
+				// secret exists but etcdcluster status field doesn't contain the secret name: can happen only after move
+				// set the Secret name on etcdCluster and update it so it receives a sync
+				if err := unstructured.SetNestedField(obj.Object, etcdSecretName, "status", "initMachineAddress"); err != nil {
+					return ctrl.Result{}, err
+				}
+				// set Initialized to true on etcdCluster and update it so it receives a sync
+				if err := unstructured.SetNestedField(obj.Object, true, "status", "initialized"); err != nil {
+					return ctrl.Result{}, err
+				}
+				// Always attempt to Patch the external object.
+				if err := patchHelper.Patch(ctx, obj); err != nil {
+					return ctrl.Result{}, err
+				}
+			}
+		}
+	}
+
 	// Get and set the failure domain from the infrastructure provider.
 	var failureDomain string
 	err = util.UnstructuredUnmarshalField(s.infraMachine, &failureDomain, "spec", "failureDomain")
diff --git a/internal/controllers/machine/machine_controller_status.go b/internal/controllers/machine/machine_controller_status.go
index bf03e3cb3..e9a786958 100644
--- a/internal/controllers/machine/machine_controller_status.go
+++ b/internal/controllers/machine/machine_controller_status.go
@@ -796,6 +796,13 @@ func setMachinePhaseAndLastUpdated(_ context.Context, m *clusterv1.Machine) {
 		m.Status.SetTypedPhase(clusterv1.MachinePhaseRunning)
 	}
 
+	if _, ok := m.Labels[clusterv1.MachineEtcdClusterLabelName]; ok {
+		// Status.NodeRef does not get set for etcd machines since they don't correspond to k8s node objects
+		if m.Status.InfrastructureReady {
+			m.Status.SetTypedPhase(clusterv1.MachinePhaseRunning)
+		}
+	}
+
 	// Set the phase to "failed" if any of Status.FailureReason or Status.FailureMessage is not-nil.
 	if m.Status.FailureReason != nil || m.Status.FailureMessage != nil {
 		m.Status.SetTypedPhase(clusterv1.MachinePhaseFailed)
diff --git a/util/collections/machine_filters.go b/util/collections/machine_filters.go
index be1f0d2d6..87a78f923 100644
--- a/util/collections/machine_filters.go
+++ b/util/collections/machine_filters.go
@@ -122,6 +122,18 @@ func ControlPlaneMachines(clusterName string) func(machine *clusterv1.Machine) b
 	}
 }
 
+// EtcdMachines returns a filter to find all etcd machines for a cluster, regardless of ownership.
+// Usage: GetFilteredMachinesForCluster(ctx, client, cluster, EtcdMachines(cluster.Name)).
+func EtcdMachines(clusterName string) func(machine *clusterv1.Machine) bool {
+	selector := EtcdSelectorForCluster(clusterName)
+	return func(machine *clusterv1.Machine) bool {
+		if machine == nil {
+			return false
+		}
+		return selector.Matches(labels.Set(machine.Labels))
+	}
+}
+
 // AdoptableControlPlaneMachines returns a filter to find all un-controlled control plane machines.
 // Usage: GetFilteredMachinesForCluster(ctx, client, cluster, AdoptableControlPlaneMachines(cluster.Name, controlPlane)).
 func AdoptableControlPlaneMachines(clusterName string) func(machine *clusterv1.Machine) bool {
@@ -270,6 +282,20 @@ func ControlPlaneSelectorForCluster(clusterName string) labels.Selector {
 	)
 }
 
+// EtcdSelectorForCluster returns the label selector necessary to get etcd machines for a given cluster.
+func EtcdSelectorForCluster(clusterName string) labels.Selector {
+	must := func(r *labels.Requirement, err error) labels.Requirement {
+		if err != nil {
+			panic(err)
+		}
+		return *r
+	}
+	return labels.NewSelector().Add(
+		must(labels.NewRequirement(clusterv1.ClusterNameLabel, selection.Equals, []string{clusterName})),
+		must(labels.NewRequirement(clusterv1.MachineEtcdClusterLabelName, selection.Exists, []string{})),
+	)
+}
+
 // MatchesKubernetesVersion returns a filter to find all machines that match a given Kubernetes version.
 func MatchesKubernetesVersion(kubernetesVersion string) Func {
 	return func(machine *clusterv1.Machine) bool {
diff --git a/util/secret/certificates.go b/util/secret/certificates.go
index b1d553c52..0fc42c3b8 100644
--- a/util/secret/certificates.go
+++ b/util/secret/certificates.go
@@ -431,6 +431,9 @@ func (c Certificates) AsFiles() []bootstrapv1.File {
 	if serviceAccountKey := c.GetByPurpose(ServiceAccount); serviceAccountKey != nil {
 		certFiles = append(certFiles, serviceAccountKey.AsFiles()...)
 	}
+	if managedEtcdCACertKey := c.GetByPurpose(ManagedExternalEtcdCA); managedEtcdCACertKey != nil {
+		certFiles = append(certFiles, managedEtcdCACertKey.AsFiles()...)
+	}
 
 	// these will only exist if external etcd was defined and supplied by the user
 	if apiserverEtcdClientCert := c.GetByPurpose(APIServerEtcdClient); apiserverEtcdClientCert != nil {
diff --git a/util/secret/consts.go b/util/secret/consts.go
index d50062da3..043764325 100644
--- a/util/secret/consts.go
+++ b/util/secret/consts.go
@@ -48,6 +48,8 @@ const (
 
 	// APIServerEtcdClient is the secret name of user-supplied secret containing the apiserver-etcd-client key/cert.
 	APIServerEtcdClient = Purpose("apiserver-etcd-client")
+
+	ManagedExternalEtcdCA = Purpose("managed-etcd")
 )
 
 var (
diff --git a/util/util.go b/util/util.go
index dfe38100e..6ef08e5c6 100644
--- a/util/util.go
+++ b/util/util.go
@@ -148,6 +148,12 @@ func IsNodeReady(node *corev1.Node) bool {
 	return false
 }
 
+// IsEtcdMachine checks if machine is an etcd machine.
+func IsEtcdMachine(machine *clusterv1.Machine) bool {
+	_, ok := machine.ObjectMeta.Labels[clusterv1.MachineEtcdClusterLabelName]
+	return ok
+}
+
 // GetClusterFromMetadata returns the Cluster object (if present) using the object metadata.
 func GetClusterFromMetadata(ctx context.Context, c client.Client, obj metav1.ObjectMeta) (*clusterv1.Cluster, error) {
 	if obj.Labels[clusterv1.ClusterNameLabel] == "" {
-- 
2.45.2

